{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework for MRI reconstruction (Autumn 2019)\n",
    "\n",
    "In this tutorial, we provide the data loader to read and process the MRI data in order to ease the difficulty of training your network. By providing this, we hope you focus more on methodology development. Please feel free to change it to suit what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os\n",
    "from functions import transforms as T\n",
    "from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list, acceleration, center_fraction, use_seed):\n",
    "        self.data_list = data_list\n",
    "        self.acceleration = acceleration\n",
    "        self.center_fraction = center_fraction\n",
    "        self.use_seed = use_seed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.data_list[idx]\n",
    "        return get_epoch_batch(subject_id, self.acceleration, self.center_fraction, self.use_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_batch(subject_id, acc, center_fract, use_seed=True):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name, slice = subject_id  \n",
    "    \n",
    "    with h5py.File(rawdata_name, 'r') as data:\n",
    "        rawdata = data['kspace'][slice]\n",
    "                      \n",
    "    slice_kspace = T.to_tensor(rawdata).unsqueeze(0)\n",
    "    S, Ny, Nx, ps = slice_kspace.shape\n",
    "\n",
    "    # apply random mask\n",
    "    shape = np.array(slice_kspace.shape)\n",
    "    mask_func = MaskFunc(center_fractions=[center_fract], accelerations=[acc])\n",
    "    seed = None if not use_seed else tuple(map(ord, fname))\n",
    "    mask = mask_func(shape, seed)\n",
    "      \n",
    "    # undersample\n",
    "    masked_kspace = torch.where(mask == 0, torch.Tensor([0]), slice_kspace)\n",
    "    masks = mask.repeat(S, Ny, 1, ps)\n",
    "\n",
    "    img_gt, img_und = T.ifft2(slice_kspace), T.ifft2(masked_kspace)\n",
    "\n",
    "    # perform data normalization which is important for network to learn useful features\n",
    "    # during inference there is no ground truth image so use the zero-filled recon to normalize\n",
    "    norm = T.complex_abs(img_und).max()\n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "    # normalized data\n",
    "    img_gt, img_und, rawdata_und = img_gt/norm, img_und/norm, masked_kspace/norm\n",
    "        \n",
    "    return img_gt.squeeze(0), img_und.squeeze(0), rawdata_und.squeeze(0), masks.squeeze(0), norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "    \n",
    "        for fname in sorted(os.listdir(which_data_path)):\n",
    "            \n",
    "            subject_data_path = os.path.join(which_data_path, fname)\n",
    "                     \n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "            with h5py.File(subject_data_path, 'r') as data:\n",
    "                num_slice = data['kspace'].shape[0]\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(fname, subject_data_path, slice) for slice in range(5, num_slice)]\n",
    "    \n",
    "    return data_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'kspace' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2d47b304e464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_path_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/just4/OneDrive/Documents/NC2019MRI/train'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata_path_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/just4/OneDrive/Documents/NC2019MRI/test'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# first load all file names, paths and slices.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-4c9a5d9448df>\u001b[0m in \u001b[0;36mload_data_path\u001b[1;34m(train_data_path, val_data_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_data_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mnum_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kspace'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# the first 5 slices are mostly noise so it is better to exlude them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nc\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (object 'kspace' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    data_path_train = 'C:/Users/just4/OneDrive/Documents/NC2019MRI/train'\n",
    "    data_path_val = 'C:/Users/just4/OneDrive/Documents/NC2019MRI/test'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n",
    "\n",
    "    acc = 8\n",
    "    cen_fract = 0.04\n",
    "    seed = False # random masks for each slice \n",
    "    num_workers = 12 # data loading is faster using a bigger number for num_workers. 0 means using one cpu to load data\n",
    "    \n",
    "    # create data loader for training set. It applies same to validation set as well\n",
    "    train_dataset = MRIDataset(data_list['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1, num_workers=num_workers) \n",
    "    for iteration, sample in enumerate(train_loader):\n",
    "        \n",
    "        img_gt, img_und, rawdata_und, masks, norm = sample\n",
    "         \n",
    "        # stack different slices into a volume for visualisation\n",
    "        A = masks[...,0].squeeze()\n",
    "        B = torch.log(T.complex_abs(rawdata_und) + 1e-9).squeeze()\n",
    "        C = T.complex_abs(img_und).squeeze()\n",
    "        D = T.complex_abs(img_gt).squeeze()\n",
    "        all_imgs = torch.stack([A,B,C,D], dim=0)\n",
    "\n",
    "        # from left to right: mask, masked kspace, undersampled image, ground truth\n",
    "        show_slices(all_imgs, [0, 1, 2, 3], cmap='gray')\n",
    "        plt.pause(1)\n",
    "\n",
    "        if iteration >= 3: break  # show 4 random slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
