1 0 1.72417414188385
1 200 0.531028094279803
1 400 0.3011888911045477
1 600 0.2998615955009564
1 800 0.2539704293171362
1 1000 0.2457558309266298
1 1200 0.24184570256099153
1 1400 0.2787568267807103
1 1600 0.23003401932794856
1 1800 0.24505145858287594
1 2000 0.2514351668989716

Train Epoch: 1 Average training loss: 0.3356 

2 0 0.4056549072265625
2 200 0.2767608800164272
2 400 0.24527892827224468
2 600 0.25336948646630875
2 800 0.23051649763627963
2 1000 0.22588896999726948
2 1200 0.2223220051965289
2 1400 0.24891984942453305
2 1600 0.2431066951382299
2 1800 0.25148125433979046
2 2000 0.2303420810559233

Train Epoch: 2 Average training loss: 0.2457 

3 0 0.15558013319969177
3 200 0.22039531564395393
3 400 0.22304711587919174
3 600 0.24691933088498316
3 800 0.2331668035333344
3 1000 0.2395491580590233
3 1200 0.24172733807669275
3 1400 0.24235289896789375
3 1600 0.21832612492737846
3 1800 0.24347197820937214
3 2000 0.22410217986422676

Train Epoch: 3 Average training loss: 0.2288 

4 0 0.28885066509246826
4 200 0.2308095170682351
4 400 0.23352918666189693
4 600 0.22735733047128812
4 800 0.22831419712664713
4 1000 0.22287320718675374
4 1200 0.2200003186306443
4 1400 0.23441808225683583
4 1600 0.2410200487435223
4 1800 0.2133625928578484
4 2000 0.21804978477261683

Train Epoch: 4 Average training loss: 0.2312 

5 0 0.27453964948654175
5 200 0.22174905067457398
5 400 0.23504449942932207
5 600 0.22713498854947045
5 800 0.22558096656005605
5 1000 0.23175652079045972
5 1200 0.23815740212718287
5 1400 0.2152961041577693
5 1600 0.22080353577633177
5 1800 0.20806744122385237
5 2000 0.23109172205468956

Train Epoch: 5 Average training loss: 0.2296 

6 0 0.10356399416923523
6 200 0.2175466846866044
6 400 0.2364533368844697
6 600 0.21532674741971164
6 800 0.22385515283400506
6 1000 0.2131699683525411
6 1200 0.23860754768481185
6 1400 0.23686913440791
6 1600 0.2111523450293538
6 1800 0.222514532002292
6 2000 0.2376413183487429

Train Epoch: 6 Average training loss: 0.2181 

7 0 0.21038655936717987
7 200 0.22178326394061504
7 400 0.23174831830554093
7 600 0.2209635872569912
7 800 0.20459438881291583
7 1000 0.21615036231659696
7 1200 0.20758867943769066
7 1400 0.21434305755509708
7 1600 0.22497109117734063
7 1800 0.23865098015930314
7 2000 0.23178588499765226

Train Epoch: 7 Average training loss: 0.2206 

8 0 0.06329450756311417
8 200 0.19809614965463387
8 400 0.21550476307576272
8 600 0.24748958407446559
8 800 0.24440787029615657
8 1000 0.20710918451379698
8 1200 0.2254912859887346
8 1400 0.2113350229138096
8 1600 0.20995385441318787
8 1800 0.21670486142439535
8 2000 0.2235211718093689

Train Epoch: 8 Average training loss: 0.2116 

9 0 0.4613412618637085
9 200 0.2371408306610621
9 400 0.2222083679989733
9 600 0.20311692643216916
9 800 0.222081257435934
9 1000 0.21909793162238406
9 1200 0.2229773794886564
9 1400 0.22167035288560744
9 1600 0.20808044259004826
9 1800 0.2149342453958319
9 2000 0.23780127501101264

Train Epoch: 9 Average training loss: 0.2280 

10 0 0.12090639024972916
10 200 0.19814303346895654
10 400 0.20586850218363786
10 600 0.22048507279361668
10 800 0.223471214807677
10 1000 0.21992780558496802
10 1200 0.20357037034518818
10 1400 0.2054197287069942
10 1600 0.19893610034790565
10 1800 0.22029570897595238
10 2000 0.21519668239695736

Train Epoch: 10 Average training loss: 0.2106 

11 0 0.2042076736688614
11 200 0.21790413890315943
11 400 0.20817861101930754
11 600 0.22508780974304213
11 800 0.21999086198271456
11 1000 0.2056368548713852
11 1200 0.22409849863370057
11 1400 0.2286300055399879
11 1600 0.19030551353357428
11 1800 0.20491953463326806
11 2000 0.20555628764600184

Train Epoch: 11 Average training loss: 0.2158 

12 0 0.0682411789894104
12 200 0.1691721869094155
12 400 0.1954300796617365
12 600 0.24377983437174713
12 800 0.21383747757643642
12 1000 0.21171101459377953
12 1200 0.23191006329727437
12 1400 0.22507256481485768
12 1600 0.2233624657974398
12 1800 0.22560375483338685
12 2000 0.20846124362084484

Train Epoch: 12 Average training loss: 0.2074 

13 0 0.15520355105400085
13 200 0.2144217219608341
13 400 0.2318420724533299
13 600 0.20535214313412106
13 800 0.2037990067565355
13 1000 0.21552590851505463
13 1200 0.2038593273362287
13 1400 0.2048234814618281
13 1600 0.20232217766988736
13 1800 0.21559133018895865
13 2000 0.2146480844900155

Train Epoch: 13 Average training loss: 0.2119 

14 0 0.1329481154680252
14 200 0.20316237413911922
14 400 0.22184506856619698
14 600 0.201352936122054
14 800 0.21254346713206013
14 1000 0.20511836836869146
14 1200 0.21354424342395953
14 1400 0.21878412393986338
14 1600 0.20625802530596693
14 1800 0.2199408208340102
14 2000 0.21526227392221733

Train Epoch: 14 Average training loss: 0.2092 

15 0 0.2830895185470581
15 200 0.23010924456571008
15 400 0.21826858404527624
15 600 0.20431198635305758
15 800 0.19032167259093039
15 1000 0.19049254699416793
15 1200 0.21731532847232898
15 1400 0.23289620528020585
15 1600 0.22990252867906233
15 1800 0.2256738993828039
15 2000 0.210470287711353

Train Epoch: 15 Average training loss: 0.2172 

16 0 0.08393247425556183
16 200 0.1934264034282213
16 400 0.1949824083081297
16 600 0.23261337959777914
16 800 0.21209014789152497
16 1000 0.19754033529032358
16 1200 0.19413574145040616
16 1400 0.21327403227648592
16 1600 0.22160053666219046
16 1800 0.2314047187825029
16 2000 0.2189731747207063

Train Epoch: 16 Average training loss: 0.2038 

17 0 0.18650059401988983
17 200 0.20589945537095686
17 400 0.21263734193990996
17 600 0.21800013028800458
17 800 0.2269858518281063
17 1000 0.22270925403693637
17 1200 0.2133147170620044
17 1400 0.20723092879609384
17 1600 0.20563425738052765
17 1800 0.20057601847872641
17 2000 0.19968825801733392

Train Epoch: 17 Average training loss: 0.2107 

18 0 0.1526898443698883
18 200 0.19962142584387402
18 400 0.2003535600907185
18 600 0.21526824908044895
18 800 0.23367530625877128
18 1000 0.23547245680839735
18 1200 0.1832892984594929
18 1400 0.18349002921388705
18 1600 0.22342392428781999
18 1800 0.2235911269118312
18 2000 0.20571925044380973

Train Epoch: 18 Average training loss: 0.2086 

19 0 0.4352850615978241
19 200 0.2366149882142115
19 400 0.19892995736677843
19 600 0.20211510145829995
19 800 0.179762209673569
19 1000 0.22012616311683322
19 1200 0.23019239816253861
19 1400 0.22767549830852787
19 1600 0.22162243243316782
19 1800 0.2055557329846078
19 2000 0.213105872130102

Train Epoch: 19 Average training loss: 0.2202 

20 0 0.21480335295200348
20 200 0.19670559946912086
20 400 0.2000849982952677
20 600 0.21030400139345612
20 800 0.21458835179068064
20 1000 0.21180621082331286
20 1200 0.212170022667993
20 1400 0.21048333677238992
20 1600 0.19947152689880826
20 1800 0.2126312057136982
20 2000 0.21054719183802753

Train Epoch: 20 Average training loss: 0.2115 

21 0 0.1206560879945755
21 200 0.2112810419675554
21 400 0.18977973377648158
21 600 0.21781212625201873
21 800 0.2020420463978139
21 1000 0.21628427406043874
21 1200 0.20224735167495003
21 1400 0.2161424913541614
21 1600 0.20915675014577148
21 1800 0.21950968514480682
21 2000 0.19479373245874787

Train Epoch: 21 Average training loss: 0.2058 

22 0 0.1916959434747696
22 200 0.20575986975456773
22 400 0.20554445235445212
22 600 0.22226005176265587
22 800 0.22100388271379426
22 1000 0.20847560955895902
22 1200 0.19761853714963767
22 1400 0.20426291948419303
22 1600 0.20681546524764652
22 1800 0.2065257555281863
22 2000 0.21302139501473477

Train Epoch: 22 Average training loss: 0.2082 

23 0 0.15971951186656952
23 200 0.20612576179664527
23 400 0.2190577088414202
23 600 0.2144484653454887
23 800 0.20711653549731857
23 1000 0.20350369856400397
23 1200 0.19459770280920374
23 1400 0.21157632804490437
23 1600 0.2130869022110446
23 1800 0.23390416744952813
23 2000 0.20425814777941959

Train Epoch: 23 Average training loss: 0.2072 

24 0 0.1022949144244194
24 200 0.2127645318538052
24 400 0.2109289623304041
24 600 0.20209513432487952
24 800 0.21605716733899985
24 1000 0.2018254607060125
24 1200 0.1775733630265246
24 1400 0.2195528741226992
24 1600 0.20111038557241376
24 1800 0.2021633196745273
24 2000 0.21165180468355124

Train Epoch: 24 Average training loss: 0.2031 

25 0 0.12049552798271179
25 200 0.20261326419824055
25 400 0.20198725145825808
25 600 0.21061167050901286
25 800 0.1953530858883488
25 1000 0.20545838285105186
25 1200 0.20005799429467022
25 1400 0.21824204330996377
25 1600 0.21095378915691385
25 1800 0.22410961935098409
25 2000 0.20900680445171707

Train Epoch: 25 Average training loss: 0.2040 

26 0 0.5872233510017395
26 200 0.27075348889014117
26 400 0.22865052204483247
26 600 0.19715011068740732
26 800 0.19896650117448142
26 1000 0.21952238471021995
26 1200 0.22553254798401393
26 1400 0.19311814631505786
26 1600 0.20888528618468682
26 1800 0.2128202143161065
26 2000 0.21223519820501718

Train Epoch: 26 Average training loss: 0.2271 

27 0 0.18871670961380005
27 200 0.20963082243977116
27 400 0.20879567841970126
27 600 0.23570192651904387
27 800 0.21358004666584174
27 1000 0.232621837971182
27 1200 0.20679386332992417
27 1400 0.1967013222199103
27 1600 0.18502052072519265
27 1800 0.21206030713852844
27 2000 0.19952350167457517

Train Epoch: 27 Average training loss: 0.2074 

28 0 0.3238292634487152
28 200 0.2145862529569834
28 400 0.23043179043962583
28 600 0.21316395553768155
28 800 0.19785947285853475
28 1000 0.21115951290093676
28 1200 0.1994103712011993
28 1400 0.21266721155112736
28 1600 0.22437815879664422
28 1800 0.19507923139257935
28 2000 0.2130765769191717

Train Epoch: 28 Average training loss: 0.2128 

29 0 0.06907513737678528
29 200 0.181393174435324
29 400 0.18700929564480007
29 600 0.1947769951285154
29 800 0.193272453471877
29 1000 0.20453817983718037
29 1200 0.1978769778454526
29 1400 0.20969975015278208
29 1600 0.21873616386225456
29 1800 0.22039667090111612
29 2000 0.21681440424703474

Train Epoch: 29 Average training loss: 0.1987 

30 0 0.09224428236484528
30 200 0.1819385481696381
30 400 0.19596876339750677
30 600 0.22020876963248773
30 800 0.22430912248851254
30 1000 0.20976785026918449
30 1200 0.2022010326141463
30 1400 0.19845040460618152
30 1600 0.20043677271361335
30 1800 0.19906471168519607
30 2000 0.20753570879589073

Train Epoch: 30 Average training loss: 0.2001 

31 0 0.2297089397907257
31 200 0.20566844745263843
31 400 0.19164449963513075
31 600 0.20517870842883337
31 800 0.20307121760276003
31 1000 0.2017205506864572
31 1200 0.20981706890001128
31 1400 0.20605731260645355
31 1600 0.20137428062384743
31 1800 0.20288890554744662
31 2000 0.1982752654247983

Train Epoch: 31 Average training loss: 0.2066 

32 0 0.0781208723783493
32 200 0.18556367863308154
32 400 0.1701605292269395
32 600 0.1889772386710511
32 800 0.2133099896494511
32 1000 0.19802004801848108
32 1200 0.20167374686342268
32 1400 0.2000412021329848
32 1600 0.21237898614638312
32 1800 0.2304040078573086
32 2000 0.21184410922347152

Train Epoch: 32 Average training loss: 0.1975 

33 0 0.35408127307891846
33 200 0.2324965021728154
33 400 0.2351400843828205
33 600 0.20170990833070343
33 800 0.21209832872452788
33 1000 0.22293304252438179
33 1200 0.19603816623954967
33 1400 0.20602833454522265
33 1600 0.21531736259583004
33 1800 0.21996966359107745
33 2000 0.18304476691662772

Train Epoch: 33 Average training loss: 0.2132 

34 0 0.10002388060092926
34 200 0.18966817572222616
34 400 0.18791061263466852
34 600 0.20287938969873603
34 800 0.21741562043360418
34 1000 0.21272297979217886
34 1200 0.20627043379530086
34 1400 0.20080883817241846
34 1600 0.20773423178583098
34 1800 0.22472025931623105
34 2000 0.19146504646977663

Train Epoch: 34 Average training loss: 0.1995 

35 0 0.1827811747789383
35 200 0.21301688936290272
35 400 0.2204350234653739
35 600 0.2131734790986139
35 800 0.21743185523279887
35 1000 0.19960137805016429
35 1200 0.2053783014092945
35 1400 0.21749501653381975
35 1600 0.1989818217955971
35 1800 0.19758959089565142
35 2000 0.18602607982394181

Train Epoch: 35 Average training loss: 0.2051 

