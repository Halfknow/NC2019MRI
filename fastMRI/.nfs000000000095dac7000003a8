1 0 1.4588758945465088
1 200 0.47126397464510816
1 400 0.32139527295537546
1 600 0.2813432649188528
1 800 0.29622386116942306
1 1000 0.26118713705760166
1 1200 0.2710255329799306
1 1400 0.24638820978634576
1 1600 0.24650806193799077
1 1800 0.2787630947248814
1 2000 0.23917892440343377

Train Epoch: 1 Average training loss: 0.3288 

2 0 0.3685965836048126
2 200 0.2536934911075343
2 400 0.27224255922899204
2 600 0.24869523932237
2 800 0.2261374861395922
2 1000 0.2435552456066195
2 1200 0.2345382039690162
2 1400 0.23396287862145437
2 1600 0.23465328557220588
2 1800 0.2187155155824029
2 2000 0.24082060996262614

Train Epoch: 2 Average training loss: 0.2445 

3 0 0.13503092527389526
3 200 0.20876886113651932
3 400 0.23950191308781663
3 600 0.2513036982610761
3 800 0.23482353272159318
3 1000 0.2155431666313258
3 1200 0.23007098806823975
3 1400 0.2299201788583139
3 1600 0.24278722502799951
3 1800 0.24253388470620943
3 2000 0.22244163883164841

Train Epoch: 3 Average training loss: 0.2271 

4 0 0.13310173153877258
4 200 0.2077377454580553
4 400 0.22239160183593779
4 600 0.23820524217937736
4 800 0.21517274520064517
4 1000 0.2229824446704763
4 1200 0.23939286187993158
4 1400 0.2358494995544905
4 1600 0.23322107828717933
4 1800 0.2304741284076555
4 2000 0.21486593115042785

Train Epoch: 4 Average training loss: 0.2246 

5 0 0.08950842171907425
5 200 0.20282491623187515
5 400 0.237660212244744
5 600 0.24976873420098178
5 800 0.24150622771447075
5 1000 0.23697949616706265
5 1200 0.23511275093336603
5 1400 0.2155792113555686
5 1600 0.2102945762605932
5 1800 0.21596792913991059
5 2000 0.22533400239801532

Train Epoch: 5 Average training loss: 0.2198 

6 0 0.12168031930923462
6 200 0.20484944637845467
6 400 0.21320522484688045
6 600 0.2145664841582679
6 800 0.21996073762459578
6 1000 0.23166361141550373
6 1200 0.2178029651385035
6 1400 0.22736316686399785
6 1600 0.2244268515639799
6 1800 0.2351770887250952
6 2000 0.24399443887403127

Train Epoch: 6 Average training loss: 0.2173 

7 0 0.09366685897111893
7 200 0.213794494234426
7 400 0.20144321482509842
7 600 0.21622296964735713
7 800 0.21044033547228141
7 1000 0.2195807299633339
7 1200 0.22709258341139954
7 1400 0.2166596720400113
7 1600 0.22858951436666333
7 1800 0.2172846121572382
7 2000 0.23427455125315902

Train Epoch: 7 Average training loss: 0.2157 

8 0 0.42628127336502075
8 200 0.24199942143771763
8 400 0.21989316928487185
8 600 0.2086140188682876
8 800 0.20427597313827067
8 1000 0.20748270104108543
8 1200 0.21376894073169916
8 1400 0.20177289286047878
8 1600 0.2285003071850333
8 1800 0.22774876930939944
8 2000 0.21205175000229207

Train Epoch: 8 Average training loss: 0.2273 

9 0 0.09608583152294159
9 200 0.2034273119458274
9 400 0.22073861411595358
9 600 0.23473233565782964
9 800 0.2251376399214536
9 1000 0.19802505987080746
9 1200 0.21525755448920003
9 1400 0.1997974223644602
9 1600 0.2240366806717705
9 1800 0.21228421621551968
9 2000 0.2171791989613536

Train Epoch: 9 Average training loss: 0.2126 

10 0 0.09436661005020142
10 200 0.20146645981273617
10 400 0.2118456420361128
10 600 0.2106305526554489
10 800 0.20658878105056724
10 1000 0.21627918085365025
10 1200 0.21552393833843314
10 1400 0.25102104659926167
10 1600 0.2147024902504411
10 1800 0.2170880961222199
10 2000 0.2210144702775146

Train Epoch: 10 Average training loss: 0.2098 

11 0 0.2830132842063904
11 200 0.22090020708789024
11 400 0.23370851886663074
11 600 0.2163408417296235
11 800 0.20982737198015636
11 1000 0.19618634652778755
11 1200 0.20630762013519047
11 1400 0.21076364938717806
11 1600 0.22612832946982186
11 1800 0.21753024486792988
11 2000 0.23058527268898868

Train Epoch: 11 Average training loss: 0.2174 

12 0 0.06138882786035538
12 200 0.18318886772012885
12 400 0.20880662657882554
12 600 0.2131530476993539
12 800 0.21928889077389582
12 1000 0.22457395203641306
12 1200 0.21283921997695415
12 1400 0.21031091717747202
12 1600 0.20752555639181305
12 1800 0.21744872057965345
12 2000 0.21448362429044773

Train Epoch: 12 Average training loss: 0.2060 

13 0 0.2765313684940338
13 200 0.20916895800764074
13 400 0.21980943905942021
13 600 0.23064973134157818
13 800 0.20837304043499358
13 1000 0.20375268859994483
13 1200 0.19955598924151183
13 1400 0.21379783702508112
13 1600 0.21776347077874234
13 1800 0.20370034638477152
13 2000 0.21236734131174065

Train Epoch: 13 Average training loss: 0.2151 

14 0 0.24076980352401733
14 200 0.2156725449938912
14 400 0.20114574537093602
14 600 0.2093269318156903
14 800 0.23820038546962924
14 1000 0.20428349364712942
14 1200 0.21170490242802806
14 1400 0.20002261000720548
14 1600 0.22554197469295512
14 1800 0.21509189360645647
14 2000 0.21672765782312128

Train Epoch: 14 Average training loss: 0.2139 

15 0 0.057419851422309875
15 200 0.19455253813783774
15 400 0.215024574108652
15 600 0.20095180421426764
15 800 0.18945537444442456
15 1000 0.1927917660007954
15 1200 0.22892269857042744
15 1400 0.22886559449802327
15 1600 0.21008931589592203
15 1800 0.21107042747448637
15 2000 0.1970101662587805

Train Epoch: 15 Average training loss: 0.2046 

16 0 0.38136112689971924
16 200 0.24296042197352394
16 400 0.20657181038105474
16 600 0.23250654331106718
16 800 0.19378074770891832
16 1000 0.20258063691943629
16 1200 0.18732130880116585
16 1400 0.21438878173272963
16 1600 0.20474585529529507
16 1800 0.24076598028291757
16 2000 0.21779485436263707

Train Epoch: 16 Average training loss: 0.2189 

17 0 0.31989097595214844
17 200 0.24101172851550975
17 400 0.22407289068158914
17 600 0.21261234077895583
17 800 0.22446782867955253
17 1000 0.21615073771768323
17 1200 0.20584892899742074
17 1400 0.1959236006599003
17 1600 0.19930377877342834
17 1800 0.20570165058115963
17 2000 0.20805067192130403

Train Epoch: 17 Average training loss: 0.2161 

18 0 0.17394885420799255
18 200 0.19424177963772904
18 400 0.2212706447493173
18 600 0.2242765508950986
18 800 0.2168201440393772
18 1000 0.19943610714355167
18 1200 0.2295628935000433
18 1400 0.1950317217818016
18 1600 0.2147817366584792
18 1800 0.22526374106648747
18 2000 0.19402945036188282

Train Epoch: 18 Average training loss: 0.2089 

19 0 0.2904476523399353
19 200 0.2311498372425637
19 400 0.23516143453092184
19 600 0.22062619364669026
19 800 0.20577535863850877
19 1000 0.22676838634769209
19 1200 0.20510282665006493
19 1400 0.20389659705077975
19 1600 0.2043964463348664
19 1800 0.20114965539923804
19 2000 0.19639889680743566

Train Epoch: 19 Average training loss: 0.2139 

20 0 0.10622204095125198
20 200 0.18729043125528363
20 400 0.2005867343815825
20 600 0.20393625245664773
20 800 0.20687392010133987
20 1000 0.20071771762669868
20 1200 0.2289952934619103
20 1400 0.20894438857718073
20 1600 0.22160825599886175
20 1800 0.22254593703430656
20 2000 0.22964850198328607

Train Epoch: 20 Average training loss: 0.2038 

21 0 0.15948033332824707
21 200 0.18632052319255707
21 400 0.1854927931340793
21 600 0.1998470356079523
21 800 0.2035881731107029
21 1000 0.22524940833468607
21 1200 0.19281877117648966
21 1400 0.21472189102372236
21 1600 0.2150094258907024
21 1800 0.2197257036783492
21 2000 0.2293436119973153

Train Epoch: 21 Average training loss: 0.2068 

22 0 0.11837287992238998
22 200 0.19086364794082025
22 400 0.18690518532685535
22 600 0.19068418652053887
22 800 0.2022361008666757
22 1000 0.1950862218864525
22 1200 0.21988960064436022
22 1400 0.20103148730344728
22 1600 0.20697869006707773
22 1800 0.2112137128455351
22 2000 0.2061274936691329

Train Epoch: 22 Average training loss: 0.2032 

23 0 0.25074464082717896
23 200 0.2294764981237558
23 400 0.22301725876563439
23 600 0.20142558852106296
23 800 0.2028893330595906
23 1000 0.19206114390450177
23 1200 0.20002028003313807
23 1400 0.21703739901240532
23 1600 0.20753900318478993
23 1800 0.2173988825178297
23 2000 0.19564305439048338

Train Epoch: 23 Average training loss: 0.2101 

24 0 0.03847332298755646
24 200 0.1968650415868305
24 400 0.19870300533705607
24 600 0.20949832914711378
24 800 0.1962886031448998
24 1000 0.19036004318955002
24 1200 0.21279407860439212
24 1400 0.20570765811997282
24 1600 0.2081150588712326
24 1800 0.21147783380151064
24 2000 0.19427862195426296

Train Epoch: 24 Average training loss: 0.1980 

25 0 0.137593612074852
25 200 0.20187431891882102
25 400 0.23438492588452015
25 600 0.20153805503028982
25 800 0.19603917099786553
25 1000 0.20370964148018714
25 1200 0.20264695566542903
25 1400 0.1985008292068033
25 1600 0.22491586196843552
25 1800 0.192470662523945
25 2000 0.19766826005351787

Train Epoch: 25 Average training loss: 0.2028 

26 0 0.2097655087709427
26 200 0.20247663930015225
26 400 0.21522831596354836
26 600 0.22070807100449588
26 800 0.2010175964127435
26 1000 0.19999123484287132
26 1200 0.2115097686416094
26 1400 0.21849064109503594
26 1600 0.20892795558030508
26 1800 0.20322419017659163
26 2000 0.18828816469906437

Train Epoch: 26 Average training loss: 0.2069 

27 0 0.1753554791212082
27 200 0.1925416069829134
27 400 0.20245790534550823
27 600 0.2231760334594909
27 800 0.20449266755316212
27 1000 0.1990381818168535
27 1200 0.20534979903765097
27 1400 0.22990961438206756
27 1600 0.19512210066861263
27 1800 0.20028707489413525
27 2000 0.1916632427279526

Train Epoch: 27 Average training loss: 0.2050 

28 0 0.09341065585613251
28 200 0.19036603735939212
28 400 0.20284461442456117
28 600 0.20836000503997318
28 800 0.20699519246354986
28 1000 0.1941379920202245
28 1200 0.21121257875768665
28 1400 0.20066628415412474
28 1600 0.2095508828578592
28 1800 0.21060393410029865
28 2000 0.2123013503840347

Train Epoch: 28 Average training loss: 0.1992 

29 0 0.1461412012577057
29 200 0.18843730310445553
29 400 0.20356574952841822
29 600 0.21893950586760388
29 800 0.19533321065984663
29 1000 0.18503592512567127
29 1200 0.20567327282865552
29 1400 0.20252079410598323
29 1600 0.19875976683593963
29 1800 0.20926435602446777
29 2000 0.22253604284851278

Train Epoch: 29 Average training loss: 0.2013 

30 0 0.041010692715644836
30 200 0.2040068213887666
30 400 0.20054607503596522
30 600 0.19668126916900208
30 800 0.222391019556226
30 1000 0.2282114952124091
30 1200 0.19967607844249063
30 1400 0.19702239286240072
30 1600 0.20995074708411154
30 1800 0.20011014471088648
30 2000 0.19144559643753176

Train Epoch: 30 Average training loss: 0.1977 

31 0 0.06001348793506622
31 200 0.18594022668363455
31 400 0.21381146354145178
31 600 0.2078296346683702
31 800 0.22654232162586185
31 1000 0.21701627408173066
31 1200 0.20000277035362618
31 1400 0.183269055748431
31 1600 0.19731127298002227
31 1800 0.19458816987757474
31 2000 0.2025059540641614

Train Epoch: 31 Average training loss: 0.1993 

32 0 0.08766194432973862
32 200 0.19647619635551075
32 400 0.20375661111219023
32 600 0.19261879458267986
32 800 0.21213391195762055
32 1000 0.18638513453721953
32 1200 0.20046043218779916
32 1400 0.19297011046863877
32 1600 0.20012574325529844
32 1800 0.20386143682500035
32 2000 0.20672723690057399

Train Epoch: 32 Average training loss: 0.1980 

33 0 0.3599172830581665
33 200 0.24047595431838964
33 400 0.214354051175506
33 600 0.21257311560280093
33 800 0.19167712518756735
33 1000 0.19992614553732224
33 1200 0.17399048825924143
33 1400 0.18171547666704485
33 1600 0.19504609544611554
33 1800 0.20132380016960108
33 2000 0.2200807013554804

Train Epoch: 33 Average training loss: 0.2097 

34 0 0.4400921165943146
34 200 0.2321062250462292
34 400 0.19330933970198647
34 600 0.18906901307460316
34 800 0.21079742878827012
34 1000 0.21824104148936135
34 1200 0.20302131608707671
34 1400 0.19816314033610974
34 1600 0.21148829239110267
34 1800 0.20712776812959166
34 2000 0.20111830105185624

Train Epoch: 34 Average training loss: 0.2146 

35 0 0.17828895151615143
35 200 0.1958858249138308
35 400 0.20615028736282456
35 600 0.2104918376061332
35 800 0.222979284204058
35 1000 0.20291129838362898
35 1200 0.2002138807919601
35 1400 0.21220235669166207
35 1600 0.19101725743245399
35 1800 0.1921414059419157
35 2000 0.20337219029420472

Train Epoch: 35 Average training loss: 0.2013 

