1 0 1.6329556703567505
1 100 1.538800550350185
1 200 1.1473809514143507
1 300 0.8610163537117405
1 400 0.7381718458549722
1 500 0.5945586953414439
1 600 0.5641080135719654
1 700 0.5232034890631481
1 800 0.5477387209930518
1 900 0.5048559115974514
1 1000 0.49133013262975406
1 1100 0.538279192655739
1 1200 0.5041141673286701
1 1300 0.4949183191567477
1 1400 0.5076725232354028
1 1500 0.5003613116015908
1 1600 0.48872693277558854
1 1700 0.47500096349709336

Train Epoch: 1 Average training loss: 0.6774 

2 0 0.24722065031528473
2 100 0.36654393295069637
2 200 0.46148436311577234
2 300 0.48872642426849683
2 400 0.47192594891157846
2 500 0.4668726390596859
2 600 0.4405972500900168
2 700 0.47728448962329506
2 800 0.46706867773236455
2 900 0.457682138314697
2 1000 0.4332046246308101
2 1100 0.4080249631737463
2 1200 0.4079564830226098
2 1300 0.4045425284183537
2 1400 0.4575025553421733
2 1500 0.4725435611711421
2 1600 0.4414128490948918
2 1700 0.44707568444478524

Train Epoch: 2 Average training loss: 0.4394 

3 0 0.6739646792411804
3 100 0.5287648567914202
3 200 0.45914159834103624
3 300 0.4349172229300539
3 400 0.4867922947152179
3 500 0.43762679443277347
3 600 0.4156464246925476
3 700 0.422988076073035
3 800 0.41886203723787774
3 900 0.4205545811258844
3 1000 0.43283506052216597
3 1100 0.4737319382486967
3 1200 0.455655458742217
3 1300 0.41302955042901207
3 1400 0.4185305465477945
3 1500 0.4058386339771552
3 1600 0.4084033272451911
3 1700 0.4166047607228623

Train Epoch: 3 Average training loss: 0.4445 

4 0 0.23832298815250397
4 100 0.36898707970626365
4 200 0.4106404263426573
4 300 0.410030268269083
4 400 0.39463502140868006
4 500 0.3909723315066242
4 600 0.4057047830639415
4 700 0.40011309613002544
4 800 0.396558064969204
4 900 0.4294227041816092
4 1000 0.386829826473006
4 1100 0.4067256274882762
4 1200 0.4082932320043615
4 1300 0.4084495202483668
4 1400 0.43799960378444536
4 1500 0.449071047677674
4 1600 0.43153363389274646
4 1700 0.41776545016059247

Train Epoch: 4 Average training loss: 0.4061 

5 0 0.12577667832374573
5 100 0.28454504991344676
5 200 0.36268564089251376
5 300 0.3708682817463524
5 400 0.42830987255361125
5 500 0.4519933192055446
5 600 0.4254897694566288
5 700 0.40770013137657607
5 800 0.4005231812564215
5 900 0.3971217184268207
5 1000 0.4096538182103913
5 1100 0.4248290451874503
5 1200 0.3947732726853194
5 1300 0.3989019188500523
5 1400 0.41382451831972095
5 1500 0.40056486863425517
5 1600 0.4108263815650579
5 1700 0.40875758403502854

Train Epoch: 5 Average training loss: 0.3945 

6 0 1.233648419380188
6 100 0.7224745176852883
6 200 0.5225357922716429
6 300 0.4299191768070642
6 400 0.39434447716954296
6 500 0.3832428043667636
6 600 0.424235861484424
6 700 0.4056393219547869
6 800 0.42282118289138126
6 900 0.39950269137659344
6 1000 0.4167274086629299
6 1100 0.39376207558349746
6 1200 0.43172131678157816
6 1300 0.42472543125497353
6 1400 0.40368729009474086
6 1500 0.392045763629039
6 1600 0.4052221270516248
6 1700 0.42271079361236663

Train Epoch: 6 Average training loss: 0.4513 

7 0 0.581691563129425
7 100 0.47605424551791536
7 200 0.4214941007675045
7 300 0.38560515363339787
7 400 0.3939563927644241
7 500 0.404933239407501
7 600 0.37187390317212987
7 700 0.38766788471787755
7 800 0.3751580141139962
7 900 0.3823007397471993
7 1000 0.381293879986169
7 1100 0.3735483943038619
7 1200 0.4019628672352342
7 1300 0.38040659636866503
7 1400 0.391458450226425
7 1500 0.3963033765772552
7 1600 0.39387454692940244
7 1700 0.40497551608959426

Train Epoch: 7 Average training loss: 0.4036 

8 0 0.2106781005859375
8 100 0.3272882676133949
8 200 0.38366081394903423
8 300 0.36148079026346286
8 400 0.37693822983892517
8 500 0.3948894547827235
8 600 0.39158522891860714
8 700 0.37795834690871766
8 800 0.39340516010080184
8 900 0.3871919617719519
8 1000 0.41528419460424754
8 1100 0.3944397839812099
8 1200 0.3819616247338912
8 1300 0.3973031229931689
8 1400 0.3955711294404166
8 1500 0.37739736566157056
8 1600 0.41786083352743225
8 1700 0.3833546871247944

Train Epoch: 8 Average training loss: 0.3828 

9 0 0.7037303447723389
9 100 0.4818303598838595
9 200 0.46019307223328215
9 300 0.42045674558180723
9 400 0.40031169460649046
9 500 0.43288797784905986
9 600 0.3844912045098001
9 700 0.3809814161208535
9 800 0.37059375567101377
9 900 0.3884801164248635
9 1000 0.3837440769869284
9 1100 0.3887188081269914
9 1200 0.3749258416213261
9 1300 0.38952602055941443
9 1400 0.3917340518843833
9 1500 0.3917796141380322
9 1600 0.40061830199354054
9 1700 0.3890665475086617

Train Epoch: 9 Average training loss: 0.4082 

10 0 0.13682976365089417
10 100 0.31799059585970496
10 200 0.35885621507395465
10 300 0.34867628044124044
10 400 0.3996729160305498
10 500 0.3928772729865214
10 600 0.3828691257348295
10 700 0.3593418937585756
10 800 0.36635699970045726
10 900 0.37462873237462657
10 1000 0.4058920020902155
10 1100 0.3914070799331446
10 1200 0.35298286952991204
10 1300 0.3958118309305507
10 1400 0.4096015142050291
10 1500 0.40945789321424064
10 1600 0.37963512581675984
10 1700 0.39982097441918585

Train Epoch: 10 Average training loss: 0.3753 

11 0 0.12197525054216385
11 100 0.2703877626018049
11 200 0.3625413383778331
11 300 0.374896449232062
11 400 0.37142364273587297
11 500 0.367788678555125
11 600 0.35506227491553555
11 700 0.3744208422445525
11 800 0.3771130387821396
11 900 0.39255285297826975
11 1000 0.40962618895510106
11 1100 0.38485526179355234
11 1200 0.37965311505531385
11 1300 0.3714861515998814
11 1400 0.3689630641684107
11 1500 0.38543449916923156
11 1600 0.38514073768442636
11 1700 0.3997116731926435

Train Epoch: 11 Average training loss: 0.3676 

12 0 0.1254953294992447
12 100 0.25776251283654017
12 200 0.33012702403537175
12 300 0.3751104570374686
12 400 0.3635912078120792
12 500 0.39050127076256197
12 600 0.3751265258258882
12 700 0.36958965365699953
12 800 0.39275175253148525
12 900 0.3941293053350468
12 1000 0.4195251982498636
12 1100 0.39701028476194444
12 1200 0.3692903012188607
12 1300 0.3803352193048097
12 1400 0.37917323331381636
12 1500 0.3810859122671968
12 1600 0.3943222828176458
12 1700 0.3919822366005401

Train Epoch: 12 Average training loss: 0.3675 

13 0 0.3654731512069702
13 100 0.38019627100605274
13 200 0.40562298012721915
13 300 0.37572714178524863
13 400 0.401815481021151
13 500 0.35114336492549275
13 600 0.3543764543550124
13 700 0.3718941002883966
13 800 0.3685681804666713
13 900 0.3703868000267732
13 1000 0.3976874396620645
13 1100 0.39660536559860843
13 1200 0.3788125839222242
13 1300 0.4003629327951432
13 1400 0.39262528262188373
13 1500 0.390917276764427
13 1600 0.39833774976296804
13 1700 0.375064109302292

Train Epoch: 13 Average training loss: 0.3798 

14 0 0.29859378933906555
14 100 0.363405445121702
14 200 0.3835523761566674
14 300 0.40815001600284084
14 400 0.38161929735465705
14 500 0.370356003342613
14 600 0.412744660634644
14 700 0.38253185041914284
14 800 0.39871860772756007
14 900 0.3843033711366557
14 1000 0.36852365486496685
14 1100 0.37064906631410977
14 1200 0.36993187580101144
14 1300 0.3864229071412983
14 1400 0.37797970390814795
14 1500 0.39892369533457706
14 1600 0.3629992720077977
14 1700 0.36851956071777997

Train Epoch: 14 Average training loss: 0.3764 

15 0 0.11694185435771942
15 100 0.279103828916645
15 200 0.3620036841960704
15 300 0.36934719442147984
15 400 0.3914879253201901
15 500 0.3945201345775545
15 600 0.37851055680024503
15 700 0.37739699586800246
15 800 0.37884402929113936
15 900 0.3676814297512425
15 1000 0.3719900550428268
15 1100 0.3675984251589511
15 1200 0.37761713697367094
15 1300 0.382223347120009
15 1400 0.368745962891957
15 1500 0.36237700942269113
15 1600 0.386523787597219
15 1700 0.3757209416484424

Train Epoch: 15 Average training loss: 0.3627 

16 0 0.3307885229587555
16 100 0.3661730508349468
16 200 0.3408939009881302
16 300 0.3568243548548634
16 400 0.3650244301668605
16 500 0.3643513844496256
16 600 0.3894653466870307
16 700 0.384756679011477
16 800 0.3937520574567146
16 900 0.38315833465802945
16 1000 0.39155591520865757
16 1100 0.39702032830274614
16 1200 0.40392372243595226
16 1300 0.3676450155392436
16 1400 0.3550576280937464
16 1500 0.366467826315487
16 1600 0.37998839760225944
16 1700 0.35843833397601743

Train Epoch: 16 Average training loss: 0.3727 

17 0 0.2218976616859436
17 100 0.3043449144579073
17 200 0.3776580614597051
17 300 0.3690755538112586
17 400 0.3676646042454549
17 500 0.35851438233427224
17 600 0.39068327335193775
17 700 0.3598487492717347
17 800 0.3466043165681752
17 900 0.361784777274062
17 1000 0.382871604271381
17 1100 0.39658952258021796
17 1200 0.3924841249803242
17 1300 0.39209096199245436
17 1400 0.37817121104860474
17 1500 0.3692799494334216
17 1600 0.3635151311799182
17 1700 0.36021692692237345

Train Epoch: 17 Average training loss: 0.3672 

18 0 0.4147856533527374
18 100 0.3991268516127975
18 200 0.3995578606291663
18 300 0.3924153659290675
18 400 0.40355553525413834
18 500 0.413920099425617
18 600 0.40009246555842193
18 700 0.35485800984935223
18 800 0.3631951534957764
18 900 0.3594812029086573
18 1000 0.37047736102422874
18 1100 0.35775606710871305
18 1200 0.3458984851747952
18 1300 0.3554868844042956
18 1400 0.35548203572274434
18 1500 0.35124654046964
18 1600 0.3750914886780034
18 1700 0.3788586991960852

Train Epoch: 18 Average training loss: 0.3792 

19 0 0.1402670294046402
19 100 0.2633413613790644
19 200 0.3259685000391333
19 300 0.39360050616457
19 400 0.37702667653514355
19 500 0.42664495160514215
19 600 0.39436607515536687
19 700 0.38292363989040407
19 800 0.3666368415209025
19 900 0.3731559596345029
19 1000 0.36871966541994067
19 1100 0.36300760199995585
19 1200 0.3467846782956227
19 1300 0.3741189359142515
19 1400 0.35990034390362385
19 1500 0.3712024270974156
19 1600 0.3654019231754441
19 1700 0.3602043452588685

Train Epoch: 19 Average training loss: 0.3564 

20 0 0.7030555009841919
20 100 0.48166257230301757
20 200 0.42289464250388187
20 300 0.3961764512255519
20 400 0.3792657411064902
20 500 0.38583915496239873
20 600 0.3651331071810564
20 700 0.37772981171732956
20 800 0.3748981412644623
20 900 0.345750067003829
20 1000 0.3763119733178823
20 1100 0.3867389162493233
20 1200 0.3751207121936986
20 1300 0.37699025052208446
20 1400 0.37250537030433933
20 1500 0.3704282544981736
20 1600 0.3410942879232072
20 1700 0.3556791031464841

Train Epoch: 20 Average training loss: 0.3886 

