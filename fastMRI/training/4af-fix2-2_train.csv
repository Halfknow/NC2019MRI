1 0 1.72417414188385
1 200 0.531028094279803
1 400 0.3011888911045477
1 600 0.2998615955009564
1 800 0.2539704293171362
1 1000 0.2457558309266298
1 1200 0.24184570256099153
1 1400 0.2787568267807103
1 1600 0.23003401932794856
1 1800 0.24505145858287594
1 2000 0.2514351668989716

Train Epoch: 1 Average training loss: 0.3356 

2 0 0.4056549072265625
2 200 0.2767608800164272
2 400 0.24527892827224468
2 600 0.25336948646630875
2 800 0.23051649763627963
2 1000 0.22588896999726948
2 1200 0.2223220051965289
2 1400 0.24891984942453305
2 1600 0.2431066951382299
2 1800 0.25148125433979046
2 2000 0.2303420810559233

Train Epoch: 2 Average training loss: 0.2457 

3 0 0.15558013319969177
3 200 0.22039531564395393
3 400 0.22304711587919174
3 600 0.24691933088498316
3 800 0.2331668035333344
3 1000 0.2395491580590233
3 1200 0.24172733807669275
3 1400 0.24235289896789375
3 1600 0.21832612492737846
3 1800 0.24347197820937214
3 2000 0.22410217986422676

Train Epoch: 3 Average training loss: 0.2288 

4 0 0.28885066509246826
4 200 0.2308095170682351
4 400 0.23352918666189693
4 600 0.22735733047128812
4 800 0.22831419712664713
4 1000 0.22287320718675374
4 1200 0.2200003186306443
4 1400 0.23441808225683583
4 1600 0.2410200487435223
4 1800 0.2133625928578484
4 2000 0.21804978477261683

Train Epoch: 4 Average training loss: 0.2312 

5 0 0.27453964948654175
5 200 0.22174905067457398
5 400 0.23504449942932207
5 600 0.22713498854947045
5 800 0.22558096656005605
5 1000 0.23175652079045972
5 1200 0.23815740212718287
5 1400 0.2152961041577693
5 1600 0.22080353577633177
5 1800 0.20806744122385237
5 2000 0.23109172205468956

Train Epoch: 5 Average training loss: 0.2296 

6 0 0.10356399416923523
6 200 0.2175466846866044
6 400 0.2364533368844697
6 600 0.21532674741971164
6 800 0.22385515283400506
6 1000 0.2131699683525411
6 1200 0.23860754768481185
6 1400 0.23686913440791
6 1600 0.2111523450293538
6 1800 0.222514532002292
6 2000 0.2376413183487429

Train Epoch: 6 Average training loss: 0.2181 

7 0 0.21038655936717987
7 200 0.22178326394061504
7 400 0.23174831830554093
7 600 0.2209635872569912
7 800 0.20459438881291583
7 1000 0.21615036231659696
7 1200 0.20758867943769066
7 1400 0.21434305755509708
7 1600 0.22497109117734063
7 1800 0.23865098015930314
7 2000 0.23178588499765226

Train Epoch: 7 Average training loss: 0.2206 

8 0 0.06329450756311417
8 200 0.19809614965463387
8 400 0.21550476307576272
8 600 0.24748958407446559
8 800 0.24440787029615657
8 1000 0.20710918451379698
8 1200 0.2254912859887346
8 1400 0.2113350229138096
8 1600 0.20995385441318787
8 1800 0.21670486142439535
8 2000 0.2235211718093689

Train Epoch: 8 Average training loss: 0.2116 

9 0 0.4613412618637085
9 200 0.2371408306610621
9 400 0.2222083679989733
9 600 0.20311692643216916
9 800 0.222081257435934
9 1000 0.21909793162238406
9 1200 0.2229773794886564
9 1400 0.22167035288560744
9 1600 0.20808044259004826
9 1800 0.2149342453958319
9 2000 0.23780127501101264

Train Epoch: 9 Average training loss: 0.2280 

10 0 0.12090639024972916
10 200 0.19814303346895654
10 400 0.20586850218363786
10 600 0.22048507279361668
10 800 0.223471214807677
10 1000 0.21992780558496802
10 1200 0.20357037034518818
10 1400 0.2054197287069942
10 1600 0.19893610034790565
10 1800 0.22029570897595238
10 2000 0.21519668239695736

Train Epoch: 10 Average training loss: 0.2106 

11 0 0.2042076736688614
11 200 0.21790413890315943
11 400 0.20817861101930754
11 600 0.22508780974304213
11 800 0.21999086198271456
11 1000 0.2056368548713852
11 1200 0.22409849863370057
11 1400 0.2286300055399879
11 1600 0.19030551353357428
11 1800 0.20491953463326806
11 2000 0.20555628764600184

Train Epoch: 11 Average training loss: 0.2158 

12 0 0.0682411789894104
12 200 0.1691721869094155
12 400 0.1954300796617365
12 600 0.24377983437174713
12 800 0.21383747757643642
12 1000 0.21171101459377953
12 1200 0.23191006329727437
12 1400 0.22507256481485768
12 1600 0.2233624657974398
12 1800 0.22560375483338685
12 2000 0.20846124362084484

Train Epoch: 12 Average training loss: 0.2074 

13 0 0.15520355105400085
13 200 0.2144217219608341
13 400 0.2318420724533299
13 600 0.20535214313412106
13 800 0.2037990067565355
13 1000 0.21552590851505463
13 1200 0.2038593273362287
13 1400 0.2048234814618281
13 1600 0.20232217766988736
13 1800 0.21559133018895865
13 2000 0.2146480844900155

Train Epoch: 13 Average training loss: 0.2119 

14 0 0.1329481154680252
14 200 0.20316237413911922
14 400 0.22184506856619698
14 600 0.201352936122054
14 800 0.21254346713206013
14 1000 0.20511836836869146
14 1200 0.21354424342395953
14 1400 0.21878412393986338
14 1600 0.20625802530596693
14 1800 0.2199408208340102
14 2000 0.21526227392221733

Train Epoch: 14 Average training loss: 0.2092 

15 0 0.2830895185470581
15 200 0.23010924456571008
15 400 0.21826858404527624
15 600 0.20431198635305758
15 800 0.19032167259093039
15 1000 0.19049254699416793
15 1200 0.21731532847232898
15 1400 0.23289620528020585
15 1600 0.22990252867906233
15 1800 0.2256738993828039
15 2000 0.210470287711353

Train Epoch: 15 Average training loss: 0.2172 

16 0 0.08393247425556183
16 200 0.1934264034282213
16 400 0.1949824083081297
16 600 0.23261337959777914
16 800 0.21209014789152497
16 1000 0.19754033529032358
16 1200 0.19413574145040616
16 1400 0.21327403227648592
16 1600 0.22160053666219046
16 1800 0.2314047187825029
16 2000 0.2189731747207063

Train Epoch: 16 Average training loss: 0.2038 

17 0 0.18650059401988983
17 200 0.20589945537095686
17 400 0.21263734193990996
17 600 0.21800013028800458
17 800 0.2269858518281063
17 1000 0.22270925403693637
17 1200 0.2133147170620044
17 1400 0.20723092879609384
17 1600 0.20563425738052765
17 1800 0.20057601847872641
17 2000 0.19968825801733392

Train Epoch: 17 Average training loss: 0.2107 

18 0 0.1526898443698883
18 200 0.19962142584387402
18 400 0.2003535600907185
18 600 0.21526824908044895
18 800 0.23367530625877128
18 1000 0.23547245680839735
18 1200 0.1832892984594929
18 1400 0.18349002921388705
18 1600 0.22342392428781999
18 1800 0.2235911269118312
18 2000 0.20571925044380973

Train Epoch: 18 Average training loss: 0.2086 

19 0 0.4352850615978241
19 200 0.2366149882142115
19 400 0.19892995736677843
19 600 0.20211510145829995
19 800 0.179762209673569
19 1000 0.22012616311683322
19 1200 0.23019239816253861
19 1400 0.22767549830852787
19 1600 0.22162243243316782
19 1800 0.2055557329846078
19 2000 0.213105872130102

Train Epoch: 19 Average training loss: 0.2202 

20 0 0.21480335295200348
20 200 0.19670559946912086
20 400 0.2000849982952677
20 600 0.21030400139345612
20 800 0.21458835179068064
20 1000 0.21180621082331286
20 1200 0.212170022667993
20 1400 0.21048333677238992
20 1600 0.19947152689880826
20 1800 0.2126312057136982
20 2000 0.21054719183802753

Train Epoch: 20 Average training loss: 0.2115 

21 0 0.1206560879945755
21 200 0.2112810419675554
21 400 0.18977973377648158
21 600 0.21781212625201873
21 800 0.2020420463978139
21 1000 0.21628427406043874
21 1200 0.20224735167495003
21 1400 0.2161424913541614
21 1600 0.20915675014577148
21 1800 0.21950968514480682
21 2000 0.19479373245874787

Train Epoch: 21 Average training loss: 0.2058 

22 0 0.1916959434747696
22 200 0.20575986975456773
22 400 0.20554445235445212
22 600 0.22226005176265587
22 800 0.22100388271379426
22 1000 0.20847560955895902
22 1200 0.19761853714963767
22 1400 0.20426291948419303
22 1600 0.20681546524764652
22 1800 0.2065257555281863
22 2000 0.21302139501473477

Train Epoch: 22 Average training loss: 0.2082 

23 0 0.15971951186656952
23 200 0.20612576179664527
23 400 0.2190577088414202
23 600 0.2144484653454887
23 800 0.20711653549731857
23 1000 0.20350369856400397
23 1200 0.19459770280920374
23 1400 0.21157632804490437
23 1600 0.2130869022110446
23 1800 0.23390416744952813
23 2000 0.20425814777941959

Train Epoch: 23 Average training loss: 0.2072 

24 0 0.1022949144244194
24 200 0.2127645318538052
24 400 0.2109289623304041
24 600 0.20209513432487952
24 800 0.21605716733899985
24 1000 0.2018254607060125
24 1200 0.1775733630265246
24 1400 0.2195528741226992
24 1600 0.20111038557241376
24 1800 0.2021633196745273
24 2000 0.21165180468355124

Train Epoch: 24 Average training loss: 0.2031 

25 0 0.12049552798271179
25 200 0.20261326419824055
25 400 0.20198725145825808
25 600 0.21061167050901286
25 800 0.1953530858883488
25 1000 0.20545838285105186
25 1200 0.20005799429467022
25 1400 0.21824204330996377
25 1600 0.21095378915691385
25 1800 0.22410961935098409
25 2000 0.20900680445171707

Train Epoch: 25 Average training loss: 0.2040 

26 0 0.5872233510017395
26 200 0.27075348889014117
26 400 0.22865052204483247
26 600 0.19715011068740732
26 800 0.19896650117448142
26 1000 0.21952238471021995
26 1200 0.22553254798401393
26 1400 0.19311814631505786
26 1600 0.20888528618468682
26 1800 0.2128202143161065
26 2000 0.21223519820501718

Train Epoch: 26 Average training loss: 0.2271 

27 0 0.18871670961380005
27 200 0.20963082243977116
27 400 0.20879567841970126
27 600 0.23570192651904387
27 800 0.21358004666584174
27 1000 0.232621837971182
27 1200 0.20679386332992417
27 1400 0.1967013222199103
27 1600 0.18502052072519265
27 1800 0.21206030713852844
27 2000 0.19952350167457517

Train Epoch: 27 Average training loss: 0.2074 

28 0 0.3238292634487152
28 200 0.2145862529569834
28 400 0.23043179043962583
28 600 0.21316395553768155
28 800 0.19785947285853475
28 1000 0.21115951290093676
28 1200 0.1994103712011993
28 1400 0.21266721155112736
28 1600 0.22437815879664422
28 1800 0.19507923139257935
28 2000 0.2130765769191717

Train Epoch: 28 Average training loss: 0.2128 

29 0 0.06907513737678528
29 200 0.181393174435324
29 400 0.18700929564480007
29 600 0.1947769951285154
29 800 0.193272453471877
29 1000 0.20453817983718037
29 1200 0.1978769778454526
29 1400 0.20969975015278208
29 1600 0.21873616386225456
29 1800 0.22039667090111612
29 2000 0.21681440424703474

Train Epoch: 29 Average training loss: 0.1987 

30 0 0.09224428236484528
30 200 0.1819385481696381
30 400 0.19596876339750677
30 600 0.22020876963248773
30 800 0.22430912248851254
30 1000 0.20976785026918449
30 1200 0.2022010326141463
30 1400 0.19845040460618152
30 1600 0.20043677271361335
30 1800 0.19906471168519607
30 2000 0.20753570879589073

Train Epoch: 30 Average training loss: 0.2001 

31 0 0.2297089397907257
31 200 0.20566844745263843
31 400 0.19164449963513075
31 600 0.20517870842883337
31 800 0.20307121760276003
31 1000 0.2017205506864572
31 1200 0.20981706890001128
31 1400 0.20605731260645355
31 1600 0.20137428062384743
31 1800 0.20288890554744662
31 2000 0.1982752654247983

Train Epoch: 31 Average training loss: 0.2066 

32 0 0.0781208723783493
32 200 0.18556367863308154
32 400 0.1701605292269395
32 600 0.1889772386710511
32 800 0.2133099896494511
32 1000 0.19802004801848108
32 1200 0.20167374686342268
32 1400 0.2000412021329848
32 1600 0.21237898614638312
32 1800 0.2304040078573086
32 2000 0.21184410922347152

Train Epoch: 32 Average training loss: 0.1975 

33 0 0.35408127307891846
33 200 0.2324965021728154
33 400 0.2351400843828205
33 600 0.20170990833070343
33 800 0.21209832872452788
33 1000 0.22293304252438179
33 1200 0.19603816623954967
33 1400 0.20602833454522265
33 1600 0.21531736259583004
33 1800 0.21996966359107745
33 2000 0.18304476691662772

Train Epoch: 33 Average training loss: 0.2132 

34 0 0.10002388060092926
34 200 0.18966817572222616
34 400 0.18791061263466852
34 600 0.20287938969873603
34 800 0.21741562043360418
34 1000 0.21272297979217886
34 1200 0.20627043379530086
34 1400 0.20080883817241846
34 1600 0.20773423178583098
34 1800 0.22472025931623105
34 2000 0.19146504646977663

Train Epoch: 34 Average training loss: 0.1995 

35 0 0.1827811747789383
35 200 0.21301688936290272
35 400 0.2204350234653739
35 600 0.2131734790986139
35 800 0.21743185523279887
35 1000 0.19960137805016429
35 1200 0.2053783014092945
35 1400 0.21749501653381975
35 1600 0.1989818217955971
35 1800 0.19758959089565142
35 2000 0.18602607982394181

Train Epoch: 35 Average training loss: 0.2051 

36 0 0.09623698890209198
36 200 0.18970903332704545
36 400 0.20527648698484321
36 600 0.20957066072626498
36 800 0.18269659356800425
36 1000 0.22162372938197902
36 1200 0.21323611116957603
36 1400 0.2088966967324202
36 1600 0.20171184248841134
36 1800 0.19792716031153926
36 2000 0.2047297486932828

Train Epoch: 36 Average training loss: 0.2007 

37 0 0.1321020871400833
37 200 0.19999092368881374
37 400 0.21351148447212995
37 600 0.20339963222650456
37 800 0.19531850025663144
37 1000 0.2230083133576534
37 1200 0.2180408815660387
37 1400 0.20236852506141004
37 1600 0.20165625801275058
37 1800 0.20550732214751616
37 2000 0.2027014274867807

Train Epoch: 37 Average training loss: 0.2023 

38 0 0.09224202483892441
38 200 0.19509764023720041
38 400 0.19323157187994067
38 600 0.20469152988290815
38 800 0.19079893791237404
38 1000 0.18405352548681345
38 1200 0.20774272125563228
38 1400 0.21586855557685364
38 1600 0.21380520975272882
38 1800 0.2122203785802846
38 2000 0.19138515004204476

Train Epoch: 38 Average training loss: 0.1988 

39 0 0.11534146219491959
39 200 0.20495991931968738
39 400 0.1980940730371334
39 600 0.2076378115944788
39 800 0.20112614908735504
39 1000 0.1897222306163027
39 1200 0.19549008696117304
39 1400 0.20285348957375415
39 1600 0.21051342645662177
39 1800 0.21340253983132945
39 2000 0.2014870514557554

Train Epoch: 39 Average training loss: 0.1981 

40 0 0.17771786451339722
40 200 0.2045610719305797
40 400 0.194740078237403
40 600 0.22270746726972174
40 800 0.1991030287601386
40 1000 0.1883448919301791
40 1200 0.19210696657113313
40 1400 0.22108121716271317
40 1600 0.19493386707974805
40 1800 0.18933562140451515
40 2000 0.2039856775825455

Train Epoch: 40 Average training loss: 0.2023 

41 0 0.1330127865076065
41 200 0.21404732283314368
41 400 0.2009257458389492
41 600 0.184715566528801
41 800 0.19018244024132147
41 1000 0.21634293640007118
41 1200 0.20563048647864804
41 1400 0.20665623044374015
41 1600 0.19879575526790172
41 1800 0.18449507822094954
41 2000 0.19695147039747576

Train Epoch: 41 Average training loss: 0.2004 

42 0 0.15430369973182678
42 200 0.21147817492592955
42 400 0.2015166614704331
42 600 0.2287434197601625
42 800 0.1900215403839638
42 1000 0.19790366250351368
42 1200 0.21396314840119496
42 1400 0.19847097707413083
42 1600 0.22108543003960096
42 1800 0.21782623531426676
42 2000 0.19165849892352305

Train Epoch: 42 Average training loss: 0.2018 

43 0 0.2320091873407364
43 200 0.20233124658000093
43 400 0.21232470549404203
43 600 0.19169766475257377
43 800 0.18560391267211315
43 1000 0.1863014039348771
43 1200 0.20735447080640265
43 1400 0.20246034834622842
43 1600 0.21161662046499866
43 1800 0.18483425238284365
43 2000 0.23544216815336955

Train Epoch: 43 Average training loss: 0.2039 

44 0 0.34950244426727295
44 200 0.23764919072039212
44 400 0.22578628692536076
44 600 0.1956465885662496
44 800 0.20591558911660848
44 1000 0.18645887888835633
44 1200 0.185157590333523
44 1400 0.18207311400727041
44 1600 0.18417332932401415
44 1800 0.217459817929333
44 2000 0.18333462413079288

Train Epoch: 44 Average training loss: 0.2106 

45 0 0.07175139337778091
45 200 0.16846214148536906
45 400 0.18927421649079215
45 600 0.1962695576235128
45 800 0.21988633786614978
45 1000 0.20126742452453208
45 1200 0.19341232902246464
45 1400 0.1822069546315354
45 1600 0.23362123178490823
45 1800 0.21825294815996665
45 2000 0.21089035100992734

Train Epoch: 45 Average training loss: 0.1965 

46 0 0.04142219200730324
46 200 0.18279243471156495
46 400 0.1985347992983203
46 600 0.2018380389006645
46 800 0.22009636076773684
46 1000 0.20452684328577342
46 1200 0.21133418895748987
46 1400 0.2162814960608948
46 1600 0.22080102120522288
46 1800 0.20078876363340012
46 2000 0.19574997296343488

Train Epoch: 46 Average training loss: 0.1961 

47 0 0.4460715353488922
47 200 0.23014024842744912
47 400 0.21598121342736903
47 600 0.21259536837663748
47 800 0.19615304725626306
47 1000 0.2135179430882316
47 1200 0.19572869446207095
47 1400 0.20334270680566005
47 1600 0.19427824271292723
47 1800 0.18355298855433075
47 2000 0.19248918680376273

Train Epoch: 47 Average training loss: 0.2143 

48 0 0.14059042930603027
48 200 0.18581147278505378
48 400 0.22031636010262534
48 600 0.195966303170154
48 800 0.2346255688361178
48 1000 0.19654807993006554
48 1200 0.20901219666092075
48 1400 0.20416258289320482
48 1600 0.18996370075227761
48 1800 0.2081760796889979
48 2000 0.1956025719961092

Train Epoch: 48 Average training loss: 0.2009 

49 0 0.45194339752197266
49 200 0.2169769031230013
49 400 0.2086848318689112
49 600 0.20279035231767434
49 800 0.20604356968018436
49 1000 0.21094801324445378
49 1200 0.18930223252276784
49 1400 0.19618470743214517
49 1600 0.21345877824665221
49 1800 0.20035486646988612
49 2000 0.19902041078501298

Train Epoch: 49 Average training loss: 0.2139 

50 0 0.11593443155288696
50 200 0.17518126883655313
50 400 0.20899508447155596
50 600 0.197339714162116
50 800 0.1946513612970666
50 1000 0.1961772634078295
50 1200 0.19155294583869795
50 1400 0.21346244617688095
50 1600 0.19640293581730522
50 1800 0.21080994124756755
50 2000 0.2086440578749714

Train Epoch: 50 Average training loss: 0.1959 

