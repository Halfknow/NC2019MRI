1 0 1.7842439413070679
1 100 1.0291227964451577
1 200 0.7198867792091711
1 300 0.5587948233298851
1 400 0.511248510794182
1 500 0.48075315428178267
1 600 0.4506318679956856
1 700 0.44586304406910654
1 800 0.4387294986166818
1 900 0.4241341788115034
1 1000 0.4542094378403885
1 1100 0.43112748719938965
1 1200 0.3997974918678521
1 1300 0.43523069452902885
1 1400 0.4389689105736443
1 1500 0.4454971913514196
1 1600 0.4327516656703891
1 1700 0.40176229552317705
1 1800 0.391745436715357
1 1900 0.4314607895503091
1 2000 0.4303492937672877
1 2100 0.4512589066931796

Train Epoch: 1 Average training loss: 0.5137 

2 0 0.22337979078292847
2 100 0.35135279062604435
2 200 0.39572223918363075
2 300 0.4126981698809976
2 400 0.40904971285664005
2 500 0.42279233155386897
2 600 0.43400265089828216
2 700 0.4581724685554579
2 800 0.4403651332774543
2 900 0.42817890646990325
2 1000 0.46094139965450925
2 1100 0.4350911792633737
2 1200 0.4345285712591542
2 1300 0.42583906421984685
2 1400 0.40526900055453635
2 1500 0.44131078331548473
2 1600 0.44699784518854535
2 1700 0.41709880716227254
2 1800 0.42074791886132784
2 1900 0.43034233593483173
2 2000 0.41546580585889575
2 2100 0.3685185578689168

Train Epoch: 2 Average training loss: 0.4162 

3 0 0.3277585506439209
3 100 0.38309347706744645
3 200 0.4077884980018184
3 300 0.43453413136757935
3 400 0.4328630894624707
3 500 0.4340598070705467
3 600 0.4080750409539601
3 700 0.38118911747960094
3 800 0.3953500865532704
3 900 0.4088402990143043
3 1000 0.4152942513838477
3 1100 0.4036797790840194
3 1200 0.4074529435354993
3 1300 0.42361025768533095
3 1400 0.4217773099124542
3 1500 0.43640338941797313
3 1600 0.39670098897852873
3 1700 0.4199166021090671
3 1800 0.39623113849118446
3 1900 0.3923267211663544
3 2000 0.42106899852760626
3 2100 0.4254373054176189

Train Epoch: 3 Average training loss: 0.4104 

4 0 0.09024316817522049
4 100 0.2805091561535985
4 200 0.34239317890985754
4 300 0.3803642759770771
4 400 0.4171825309244376
4 500 0.4109706175771705
4 600 0.39613288123686524
4 700 0.37848886253099523
4 800 0.39004054001872085
4 900 0.3957018626164469
4 1000 0.39796005071259327
4 1100 0.44474792433063387
4 1200 0.42290432202100575
4 1300 0.43613695043441003
4 1400 0.4404517838768402
4 1500 0.4696452257827991
4 1600 0.4222580834154736
4 1700 0.39764872408366747
4 1800 0.40752878589537744
4 1900 0.35592894090951555
4 2000 0.39522239946286913
4 2100 0.4116940485394157

Train Epoch: 4 Average training loss: 0.3944 

5 0 0.17812557518482208
5 100 0.3156706682920111
5 200 0.3588551835029433
5 300 0.38587929104548635
5 400 0.3827697117358185
5 500 0.40780800032582226
5 600 0.4181499115032027
5 700 0.4225472132713119
5 800 0.4071492989154739
5 900 0.39937426805470444
5 1000 0.37537330496118515
5 1100 0.3955548177398173
5 1200 0.38802578737505206
5 1300 0.40289713069957106
5 1400 0.4318229812136001
5 1500 0.3795781952215583
5 1600 0.3984248411829681
5 1700 0.4104632995370772
5 1800 0.4229432735348298
5 1900 0.41232862443668117
5 2000 0.4116307738701378
5 2100 0.42058681770747625

Train Epoch: 5 Average training loss: 0.3926 

6 0 0.25232142210006714
6 100 0.38235466316050887
6 200 0.3902884369298293
6 300 0.40528134328905896
6 400 0.3979781921041471
6 500 0.38640426622914853
6 600 0.40082675999740724
6 700 0.38494862913287703
6 800 0.38043526034263364
6 900 0.39393337438535225
6 1000 0.40484757208183764
6 1100 0.3910352574780212
6 1200 0.403768211706744
6 1300 0.4118021508554993
6 1400 0.38003023159409177
6 1500 0.37545026358331113
6 1600 0.36695448781700385
6 1700 0.39231122727772927
6 1800 0.38588516242028564
6 1900 0.415659365171731
6 2000 0.40203248251470103
6 2100 0.42791387478667864

Train Epoch: 6 Average training loss: 0.3914 

7 0 0.36393195390701294
7 100 0.39611649110968467
7 200 0.39672996415336415
7 300 0.40227929863809825
7 400 0.3943136191874122
7 500 0.41583258210895646
7 600 0.4160381162281787
7 700 0.39827357267268537
7 800 0.39077295514524985
7 900 0.3409341506260992
7 1000 0.3632192887713733
7 1100 0.39678864591402085
7 1200 0.385510591625325
7 1300 0.38835155122870657
7 1400 0.3920544920377426
7 1500 0.37843566753927455
7 1600 0.4175189354415377
7 1700 0.41462370516797725
7 1800 0.4052266488794347
7 1900 0.39679887497425315
7 2000 0.3886770748784046
7 2100 0.3972896710628963

Train Epoch: 7 Average training loss: 0.3940 

8 0 0.2901128828525543
8 100 0.3388017963944494
8 200 0.3546368068319706
8 300 0.3798129039073627
8 400 0.38017541728929494
8 500 0.3791075531653525
8 600 0.38053665967740413
8 700 0.39202399844818997
8 800 0.3925250703670615
8 900 0.3924494205651664
8 1000 0.4072040141144017
8 1100 0.39060813143721934
8 1200 0.38934100800854743
8 1300 0.3866566373054026
8 1400 0.3880111175854421
8 1500 0.4330948663818506
8 1600 0.4385403315181203
8 1700 0.3850364231599924
8 1800 0.4093289281275277
8 1900 0.3978037344028585
8 2000 0.387759269417379
8 2100 0.3983877865406794

Train Epoch: 8 Average training loss: 0.3846 

9 0 0.4644765555858612
9 100 0.42467724385906813
9 200 0.3794585009704568
9 300 0.3708680771691865
9 400 0.378534204922913
9 500 0.3940691245213409
9 600 0.41226698257927524
9 700 0.4060806413932977
9 800 0.40828816844926097
9 900 0.40840193357903737
9 1000 0.40162906136904725
9 1100 0.39018774635895787
9 1200 0.3911833099204242
9 1300 0.3496440828664856
9 1400 0.3564807925093441
9 1500 0.36447742548959583
9 1600 0.3846507395309247
9 1700 0.3922707247617714
9 1800 0.38950189433549054
9 1900 0.38986701910778754
9 2000 0.4141168927662878
9 2100 0.38511610852021266

Train Epoch: 9 Average training loss: 0.3931 

10 0 0.26623469591140747
10 100 0.35655008337059896
10 200 0.38283998777605
10 300 0.37553381226536
10 400 0.3744797737346946
10 500 0.4040028879372961
10 600 0.4159546302038613
10 700 0.365415815579394
10 800 0.36512199591185746
10 900 0.34874743628190086
10 1000 0.378956267348025
10 1100 0.3711617520713256
10 1200 0.38024494082894944
10 1300 0.39129972976897304
10 1400 0.3754089365545746
10 1500 0.3928312886153175
10 1600 0.3819372435406541
10 1700 0.39259444033106083
10 1800 0.3842722285424235
10 1900 0.3886928520124618
10 2000 0.385403831672828
10 2100 0.3827513818369963

Train Epoch: 10 Average training loss: 0.3800 

11 0 1.2146285772323608
11 100 0.7252527328162284
11 200 0.5076194277619674
11 300 0.42321263014721583
11 400 0.3922546842987872
11 500 0.3460850746107674
11 600 0.40344110048072623
11 700 0.3788375601028816
11 800 0.38024771218848513
11 900 0.3781967389007615
11 1000 0.3767587309423019
11 1100 0.39076998588122397
11 1200 0.3986297161448478
11 1300 0.39956421831404315
11 1400 0.3951633180042965
11 1500 0.4019569979185145
11 1600 0.3661728056252652
11 1700 0.34577607867350174
11 1800 0.3916282879252896
11 1900 0.41185088319086854
11 2000 0.39287032472525407
11 2100 0.3801180400391004

Train Epoch: 11 Average training loss: 0.4240 

12 0 0.4078088700771332
12 100 0.3849655706696188
12 200 0.38462408510174706
12 300 0.3922244254467497
12 400 0.4049553821355345
12 500 0.39004081024060894
12 600 0.392551856955742
12 700 0.3837018187014467
12 800 0.41162402438608847
12 900 0.36572425546554227
12 1000 0.37928278095659956
12 1100 0.36348217972982505
12 1200 0.37323113807845776
12 1300 0.3896959014612274
12 1400 0.37050105684423307
12 1500 0.39173982230379945
12 1600 0.36822774962610116
12 1700 0.4001120338556567
12 1800 0.39550970066224034
12 1900 0.38498747941825195
12 2000 0.39566973804812744
12 2100 0.38375901450140876

Train Epoch: 12 Average training loss: 0.3858 

13 0 0.06548821181058884
13 100 0.2832561447952519
13 200 0.34897105986584
13 300 0.37385146979150785
13 400 0.37701349783919946
13 500 0.36437647216612673
13 600 0.3570443782889075
13 700 0.3482526672771312
13 800 0.4086891619074207
13 900 0.41567625706226324
13 1000 0.3949686979648217
13 1100 0.3847379300745159
13 1200 0.3746289215865859
13 1300 0.38185565651155295
13 1400 0.38227370861824683
13 1500 0.39239088324440624
13 1600 0.3690044400801961
13 1700 0.35498526455776114
13 1800 0.382094085229834
13 1900 0.38449906321949817
13 2000 0.3599481345390892
13 2100 0.37181122239128594

Train Epoch: 13 Average training loss: 0.3662 

14 0 0.21395276486873627
14 100 0.30902709492689023
14 200 0.3505444506710622
14 300 0.37261786624313525
14 400 0.4175121914427975
14 500 0.38574968182560515
14 600 0.3689840907744178
14 700 0.38508849191478506
14 800 0.38437496483839473
14 900 0.38217951324192445
14 1000 0.3745318868643351
14 1100 0.37143060068791584
14 1200 0.36724616745613475
14 1300 0.38898175930607876
14 1400 0.388803861368753
14 1500 0.3977310119093046
14 1600 0.38591635736654195
14 1700 0.3896887567790724
14 1800 0.38383501134659403
14 1900 0.3687297937482834
14 2000 0.38272960811114365
14 2100 0.36767147576204423

Train Epoch: 14 Average training loss: 0.3749 

15 0 0.30091872811317444
15 100 0.3379804167325481
15 200 0.3621005297205129
15 300 0.36507947376338973
15 400 0.37579815172789416
15 500 0.3689529210517481
15 600 0.3944742490472775
15 700 0.4062045237088841
15 800 0.38171234336827375
15 900 0.36234482758314346
15 1000 0.39187638856307233
15 1100 0.36321681353828483
15 1200 0.3843503213078055
15 1300 0.37498406691902547
15 1400 0.3453281930279678
15 1500 0.34460642367973315
15 1600 0.40219020423297236
15 1700 0.3901166408291018
15 1800 0.3828052912043618
15 1900 0.36950623314333675
15 2000 0.3470743222415138
15 2100 0.3730554973695964

Train Epoch: 15 Average training loss: 0.3713 

16 0 0.14010486006736755
16 100 0.29133298114434025
16 200 0.3492328519273747
16 300 0.3610882490690294
16 400 0.36810049219337676
16 500 0.3808883946123769
16 600 0.39264794078364607
16 700 0.37005954172845384
16 800 0.3996980093635273
16 900 0.40195754630944963
16 1000 0.4002719344079116
16 1100 0.39086133848143007
16 1200 0.3876404482407443
16 1300 0.382083326359592
16 1400 0.3652282435728792
16 1500 0.3430056005632378
16 1600 0.35433018761035673
16 1700 0.36177354605857587
16 1800 0.3742413679970239
16 1900 0.41157551363587275
16 2000 0.38533689402898724
16 2100 0.3729142132295995

Train Epoch: 16 Average training loss: 0.3685 

17 0 0.3048722445964813
17 100 0.34391728381012215
17 200 0.35517526217175177
17 300 0.34987467080374607
17 400 0.3929418872844724
17 500 0.4386137741948527
17 600 0.378830488094293
17 700 0.3602609631271702
17 800 0.3574905248918755
17 900 0.35632871828760576
17 1000 0.3688291048180022
17 1100 0.388397800597393
17 1200 0.35504542105257203
17 1300 0.361316738446145
17 1400 0.38114828254697963
17 1500 0.3900668780758559
17 1600 0.39560617374497814
17 1700 0.3800812730585399
17 1800 0.37244124041347887
17 1900 0.3939413981880444
17 2000 0.3950108588737516
17 2100 0.3889575012269772

Train Epoch: 17 Average training loss: 0.3741 

18 0 0.6501201391220093
18 100 0.483485282250267
18 200 0.42437926211279825
18 300 0.3642583859008402
18 400 0.36590745874448555
18 500 0.3781368492413032
18 600 0.36963961425352215
18 700 0.36772889412091986
18 800 0.37471896083837547
18 900 0.3515995640729361
18 1000 0.38147534386415205
18 1100 0.3806735674859276
18 1200 0.3602599900061404
18 1300 0.3616268117664949
18 1400 0.36109813935791757
18 1500 0.3939426376039938
18 1600 0.3792274815728759
18 1700 0.37170132074653567
18 1800 0.3924729847318985
18 1900 0.3810120275277057
18 2000 0.38474416869743916
18 2100 0.3923163073324254

Train Epoch: 18 Average training loss: 0.3909 

19 0 0.6446740627288818
19 100 0.4798837122456211
19 200 0.4451043794512673
19 300 0.40468136622814027
19 400 0.3636507591034783
19 500 0.3661918355624341
19 600 0.35184275095250633
19 700 0.3563606304754056
19 800 0.360925344328604
19 900 0.374570919342398
19 1000 0.3974067382538453
19 1100 0.3952592969885405
19 1200 0.37672395543930903
19 1300 0.3598783329025393
19 1400 0.34513471038944604
19 1500 0.364220025400889
19 1600 0.37993459315676986
19 1700 0.3903040663882233
19 1800 0.38245468931648996
19 1900 0.381434608567376
19 2000 0.4150772723722705
19 2100 0.41419183273186605

Train Epoch: 19 Average training loss: 0.3905 

20 0 0.9583949446678162
20 100 0.57931113253183
20 200 0.44508445173620687
20 300 0.407640006779754
20 400 0.3735212353373723
20 500 0.3726714815200301
20 600 0.35856011522917774
20 700 0.37475938376227713
20 800 0.34411490983279713
20 900 0.37684159824162133
20 1000 0.3933528821514328
20 1100 0.391689004144041
20 1200 0.361661440523956
20 1300 0.3698838579409926
20 1400 0.37778306393290717
20 1500 0.37382021239242796
20 1600 0.36515497380058737
20 1700 0.37615805638955885
20 1800 0.35383093487240674
20 1900 0.37822707324285687
20 2000 0.37711783002325727
20 2100 0.409835782773389

Train Epoch: 20 Average training loss: 0.3998 

21 0 0.48107215762138367
21 100 0.39950914008367583
21 200 0.3836371292264712
21 300 0.38835967872798555
21 400 0.39547419499482267
21 500 0.369844852677444
21 600 0.36025109151516066
21 700 0.3671111658114396
21 800 0.36771848187508704
21 900 0.36760032971776047
21 1000 0.38015313867374445
21 1100 0.3577647254054036
21 1200 0.3641964122326705
21 1300 0.36386606842127533
21 1400 0.344634993893973
21 1500 0.37167005803118974
21 1600 0.3808843768894556
21 1700 0.37019625240467985
21 1800 0.39945756910184904
21 1900 0.38601080288487005
21 2000 0.39727688372277675
21 2100 0.3987430551376676

Train Epoch: 21 Average training loss: 0.3784 

22 0 0.14734934270381927
22 100 0.29744970555355726
22 200 0.3590607677596669
22 300 0.3733483149288562
22 400 0.35304214703248976
22 500 0.36388981968504963
22 600 0.35595800681563844
22 700 0.3719961545886815
22 800 0.3975661667651154
22 900 0.3852508179074167
22 1000 0.3560299902077871
22 1100 0.35606102040929777
22 1200 0.36967932079504745
22 1300 0.39159601998136945
22 1400 0.39184397533593923
22 1500 0.381546836687577
22 1600 0.37322566170749105
22 1700 0.36942122010365325
22 1800 0.3587115577627982
22 1900 0.37804458843213373
22 2000 0.3718021335404069
22 2100 0.398242410350374

Train Epoch: 22 Average training loss: 0.3652 

23 0 0.18108993768692017
23 100 0.32027159936737853
23 200 0.3408657822108256
23 300 0.35330382243541686
23 400 0.35133918105611245
23 500 0.37440683606087555
23 600 0.3742951115713636
23 700 0.3790203928657879
23 800 0.367208723064447
23 900 0.3844205125971913
23 1000 0.38681823523290765
23 1100 0.37850089151473393
23 1200 0.41681940330195666
23 1300 0.3992271385737202
23 1400 0.37071685302463947
23 1500 0.3785517355918856
23 1600 0.348350105218658
23 1700 0.3330252171981426
23 1800 0.3493574679856031
23 1900 0.3723385873123919
23 2000 0.3894153565762507
23 2100 0.3973711185833403

Train Epoch: 23 Average training loss: 0.3658 

24 0 0.18783040344715118
24 100 0.2719913196603536
24 200 0.33759801453098925
24 300 0.35334294643975855
24 400 0.3776245430387038
24 500 0.3766674114964882
24 600 0.386268400997599
24 700 0.3613555681563053
24 800 0.3624423100677792
24 900 0.3537145239962988
24 1000 0.3623255982988512
24 1100 0.3798159197355474
24 1200 0.3878121360874819
24 1300 0.37768868567422087
24 1400 0.3819486042892378
24 1500 0.37949808139445346
24 1600 0.3693920409385189
24 1700 0.3869797415153949
24 1800 0.37177155177902793
24 1900 0.36901391596041805
24 2000 0.41047647705794904
24 2100 0.378686364187464

Train Epoch: 24 Average training loss: 0.3642 

25 0 0.5040678381919861
25 100 0.4490095385911097
25 200 0.40629991907304114
25 300 0.3951730326837755
25 400 0.3572536281365057
25 500 0.3876061559564345
25 600 0.35509925296821016
25 700 0.3372649581202065
25 800 0.34307977786732013
25 900 0.3697175302339058
25 1000 0.3765892040805214
25 1100 0.39823192710229993
25 1200 0.3932703154888955
25 1300 0.36440370342600364
25 1400 0.3602096996631538
25 1500 0.3741048123084934
25 1600 0.34278839840643627
25 1700 0.3736893636747901
25 1800 0.3453768826257159
25 1900 0.3857982767593648
25 2000 0.3895246437382742
25 2100 0.37166178958836465

Train Epoch: 25 Average training loss: 0.3771 

26 0 0.6815717220306396
26 100 0.48420849531427235
26 200 0.456003446523559
26 300 0.37338693761877106
26 400 0.3796218933726332
26 500 0.3762979661393814
26 600 0.3484332262702511
26 700 0.3580100807198628
26 800 0.43093367389831155
26 900 0.40359817158928013
26 1000 0.376957616213079
26 1100 0.35789867973573525
26 1200 0.35326800033542266
26 1300 0.3486014665695466
26 1400 0.3809771978646539
26 1500 0.35687929648016137
26 1600 0.3322743374086198
26 1700 0.3769930148537429
26 1800 0.3677865267251187
26 1900 0.3730885904122634
26 2000 0.3666734691047077
26 2100 0.36466314502999736

Train Epoch: 26 Average training loss: 0.3856 

27 0 0.3294895887374878
27 100 0.3572730199200476
27 200 0.34654601358366643
27 300 0.3594148115709842
27 400 0.3525577084039582
27 500 0.3592250408590451
27 600 0.4067997471300238
27 700 0.3634620011872581
27 800 0.3615485250675737
27 900 0.38185569405882885
27 1000 0.3850548763396549
27 1100 0.35631829745324656
27 1200 0.3504013072067865
27 1300 0.3839237377251527
27 1400 0.3763029732061621
27 1500 0.3733304140379704
27 1600 0.36802375509617596
27 1700 0.3543066213830538
27 1800 0.34172827696901037
27 1900 0.37268026949188215
27 2000 0.39733127908700266
27 2100 0.36566692037085213

Train Epoch: 27 Average training loss: 0.3661 

28 0 0.6990100145339966
28 100 0.478760866051925
28 200 0.42226218849547015
28 300 0.40944611980596
28 400 0.40085869200188096
28 500 0.38457203305992094
28 600 0.3786227862227097
28 700 0.37853877647219414
28 800 0.41599863642843077
28 900 0.34536553655279384
28 1000 0.3350924754121933
28 1100 0.36162851244821614
28 1200 0.361291480257637
28 1300 0.3832852062725815
28 1400 0.3954011935501384
28 1500 0.36372051750914763
28 1600 0.3794725751325496
28 1700 0.36167068495684557
28 1800 0.3528223405010672
28 1900 0.3661885055738456
28 2000 0.35501158439344005
28 2100 0.379596377858082

Train Epoch: 28 Average training loss: 0.3852 

29 0 0.25138989090919495
29 100 0.32304498345319066
29 200 0.33829017626065144
29 300 0.3672086244598028
29 400 0.375608331267153
29 500 0.3591362379921903
29 600 0.35535519767605867
29 700 0.3705605686804608
29 800 0.38513621617952837
29 900 0.37531521059114054
29 1000 0.34625602864090516
29 1100 0.3840416992054938
29 1200 0.3391366978613965
29 1300 0.3709176067145227
29 1400 0.3606726203736691
29 1500 0.36423316434403713
29 1600 0.36484237031382505
29 1700 0.36645466038836033
29 1800 0.358247761915561
29 1900 0.35008786104304146
29 2000 0.3877045342799046
29 2100 0.3785814444836223

Train Epoch: 29 Average training loss: 0.3626 

30 0 0.5919346809387207
30 100 0.4752998063058129
30 200 0.3752612114067411
30 300 0.3891271557186866
30 400 0.3749589481845323
30 500 0.3660835017072989
30 600 0.37544721062402486
30 700 0.37751903799990333
30 800 0.3638951889568102
30 900 0.33827400061785395
30 1000 0.35190488936594455
30 1100 0.3500012430476412
30 1200 0.34845222323449976
30 1300 0.36355605897208654
30 1400 0.36370079960485535
30 1500 0.37782059920109007
30 1600 0.37661052604145184
30 1700 0.3541006512963898
30 1800 0.3709421013097033
30 1900 0.3992269181710874
30 2000 0.37283907792881305
30 2100 0.37106032997171845

Train Epoch: 30 Average training loss: 0.3786 

