## Coursework main purpose:
## We would like you to propose a machine/deep learning method that is 
## able to recontruct high quality images using large acceleration rates.
## 
## The question for us: 
## how can we get sharp images using an aggressive undersampling rate ?
##
## Our mission:
## Too see how accurate your method can reconstruct an image from the 
## corresponding undersampled k-space for both undersampled rates, by
## comparing your reconstruction with the ground truth we hold.
##

# %matplotlib inline

import h5py, os
import numpy as np
from matplotlib import pyplot as plt

##
## Load the training data
##

file_path = '/home/kevinxu/Documents/NC2019MRI/train/'

for num_samples, fname in enumerate(sorted(os.listdir(file_path))):
    subject_path = os.path.join(file_path, fname)
    with h5py.File(subject_path, 'a') as hf:
        print(f'The No. {num_samples+1} file {fname} key is {list(hf.keys())}')

# Peek at one sample of k-space data

sample_path = '/home/kevinxu/Documents/NC2019MRI/train/file1000000.h5'

with h5py.File(sample_path, 'r') as hf:
    volume_kspace = hf['kspace'][()]
    print('shape:', volume_kspace.shape)
    print('dtype:', volume_kspace.dtype)
    print('sum:', volume_kspace.sum())
    print('mean:', volume_kspace.mean())
    print('std:', volume_kspace.std())

# Show slices in the sample as k-space images

def show_slices(data, slice_nums, cmap=None):
    fig = plt.figure(figsize=(15,10))
    for i, num in enumerate(slice_nums):
        plt.subplot(1, len(slice_nums), i + 1)
        plt.imshow(data[num], cmap=cmap)
        plt.axis('off')
        plt.show()

show_slices(np.log(np.abs(volume_kspace) + 1e-9), [0, 10, 20, 30], cmap='gray')

# Show slices in the sample as real images

from functions import transforms as T

volume_kspace2 = T.to_tensor(volume_kspace)
volume_image = T.ifft2(volume_kspace2)
volume_image_abs = T.complex_abs(volume_image)

show_slices(volume_image_abs, [0, 10, 20, 30], cmap='gray')

##
## Simulate under-sample data
## 

import torch
from functions.subsample import MaskFunc

# Initiate MaskFunc() for 2 AF respectively
mask_func0 = MaskFunc(center_fractions=[0.08], accelerations=[4])
mask_func1 = MaskFunc(center_fractions=[0.04], accelerations=[8])
# See subsample.py for detailed annotation for class MaskFunc().

# Call mask_func0 & 1 with an input shape of k-space(dim=4)
shape = np.array(volume_kspace2.shape)  # return array([35, 640, 368, 2])
mask0 = mask_func0(shape, seed=0)
mask1 = mask_func1(shape, seed=0)

# Apply masks to the k-space images
masked_kspace0 = torch.where(mask0 == 0, torch.Tensor([0]), volume_kspace2)
masked_kspace1 = torch.where(mask1 == 0, torch.Tensor([0]), volume_kspace2)

# Save the masks for AF=4 and AF=8
S_Num, Ny, Nx, _ = volume_kspace2.shape # return 35, 640, 368
masks0 = mask0.repeat(S_Num, Ny, 1, 1).squeeze()    # reshape back the mask
masks1 = mask1.repeat(S_Num, Ny, 1, 1).squeeze()    # to kspace shape

# Visualise masks when AF=4 & AF=8
show_slices(masks0, [5, 10, 20, 30], cmap='gray')   # masks (AF=4)
show_slices(torch.log(T.complex_abs(masked_kspace0) + 1e-9), [5,10, 20, 30], cmap='gray')

show_slices(masks1, [5, 10, 20, 30], cmap='gray')  # masks (AF=8)
show_slices(torch.log(T.complex_abs(masked_kspace1) + 1e-9), [5, 10, 20, 30], cmap='gray')

# Shapes of properties in this section
print(volume_kspace.shape)     # return (35, 640, 368)
print(volume_kspace2.shape)    # return torch.Size([35, 640, 368, 2])
print(mask0.shape)             # return torch.Size([1, 1, 368, 1])
print(masks0.shape)            # return torch.Size([35, 640, 368])

##
## Metrics
##

# Subsampled image generated by masked kspace images
sampled_image0 = T.ifft2(masked_kspace0)
sampled_image_abs0 = T.complex_abs(sampled_image0)

sampled_image1 = T.ifft2(masked_kspace1)
sampled_image_abs1 = T.complex_abs(sampled_image1)

show_slices(volume_image_abs, [5, 10, 20, 30], cmap='gray') # ground truth
show_slices(sampled_image_abs0, [5, 10, 20, 30], cmap='gray')   # AF=4
show_slices(sampled_image_abs1, [5, 10, 20, 30], cmap='gray')   # AF=8

# Crop the images to the central 320x320 pixel region
cropped_gt = T.center_crop(volume_image_abs, [320, 320])
cropped_4af = T.center_crop(sampled_image_abs0, [320, 320])
cropped_8af = T.center_crop(sampled_image_abs1, [320, 320])

show_slices(cropped_gt, [5, 10, 20, 30], cmap='gray') # ground truth
show_slices(cropped_4af, [5, 10, 20, 30], cmap='gray') # AF=4 
show_slices(cropped_8af, [5, 10, 20, 30], cmap='gray') # AF=8 

# SSIM
from skimage.measure import compare_ssim
def ssim(gt, pred):
    """ Compute structural similarity index metric (SSIM). """
    return compare_ssim(
        gt.transpose(1, 2, 0), pred.transpose(1, 2, 0), multichannel=True, data_range=gt.max())

# Compare the SSIM between undersampled real images and ground truth
print(ssim(cropped_gt.numpy(), cropped_4af.numpy()))    # AF=4
print(ssim(cropped_gt.numpy(), cropped_8af.numpy()))    # AF=8

##
## Save .h5 data
##

def save_reconstructions(reconstructions, out_dir):
    """
    Saves the reconstructions from a model into h5 files that is appropriate 
    for submission to the leaderboard.
    Args:
        reconstructions (dict[str, np.array]): 
        A dictionary mapping input filenames to corresponding reconstructions 
        (of shape num_slices x height x width).
        out_dir (pathlib.Path): 
        Path to the output directory where the reconstructions should be saved.
    """
    for fname, recons in reconstructions.items():
        subject_path = os.path.join(out_dir, fname)
        print(subject_path)
        with h5py.File(subject_path, 'w') as wf:
            wf.create_dataset('reconstruction', data=recons)

# Note that you should save your recontruction as the same name 
# as the input file name in a different directory.
# Example: 
fname0 = 'file1000000.h5'
fname1 = 'file1000001.h5'
fname2 = 'file1000002.h5'

reconstructions = [fname0: cropped_gt.numpy(), fname1: cropped_4af.numpy()]
out_dir = '../saved/'
if not (os.path.exists(out_dir)): os.makedirs(out_dir)

save_reconstructions(reconstructions, out_dir)

##
## Look into the test dataset
##

# Load the test data
file_path = '/home/kevinxu/Documents/NC2019MRI/test/'

for fname in sorted(os.listdir(file_path)):
    subject_path = os..path.join(file_path, fname)
    with h5py.File(subject_path, "r") as hf:
        print(f'file {fname} key is {list(hf.keys())}')

# Peek at one test sample
sample_path = '/home/kevinxu/Documents/NC2019MRI/test/file1000817.h5'
with h5py.File(sample_path,  "r") as hf:
    volume_kspace_4af = hf['kspace_4af'][()]
    volume_kspace_8af = hf['kspace_8af'][()]
    mask_4af = hf['mask_4af'][()]
    mask_8af = hf['mask_8af'][()]
    print(volume_kspace_4af.shape)  # return (35, 640, 372)
    print(volume_kspace_4af.dtype)  # return complex64
    print(mask_4af.shape)           # return (640, 372)
    print(mask_4af.dtype)           # return float32, *NOT Boolean*

# Visualize the masks
data = np.array([mask_4af, mask_8af])
show_slices(data, [0, 1], cmap='gray')
