{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net coding structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coding structure of our design. has five imprtant code parts. There are transforms, data loader, subsample, model and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The transforms part is consist of some functions used in this neural network. For example, fft2() and ifft2() are Fourier and inverse Fourier functions that are very critical. The two functions are used to process the k-sapce data and images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code first loads all file names, paths and slices by using the load_data_path method. Specifically, in load_data_path method, the first 5 slices are mostly noise so it is better to exclude them. And then, we set some parameters in order to set MRI data, including acceleration, central fraction, seed, number of batch and workers. The last two parameters decide speed of data loading. After that, a few slices from each volume have been randomly selected. Then, the data loader are created for training set by using function Dataloder. Finally, we stack different slices into a volume for visualization and display the mask, masked k-space, under sampled image and ground truth image on screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list, acceleration, center_fraction, use_seed):\n",
    "        self.data_list = data_list # data list imported to be processed\n",
    "        self.acceleration = acceleration # defined AF\n",
    "        self.center_fraction = center_fraction # defined CF\n",
    "        self.use_seed = use_seed # defined random or stable mask\n",
    "\n",
    "    def __len__(self): # create an attribute of the length of dataset\n",
    "        return len(self.data_list) # \n",
    "\n",
    "    def __getitem__(self, idx): # \n",
    "        subject_id = self.data_list[idx]\n",
    "        return get_epoch_batch(subject_id, self.acceleration, self.center_fraction, self.use_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_batch(subject_id, acc, center_fract, use_seed=True):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name, slice = subject_id  \n",
    "    \n",
    "    with h5py.File(rawdata_name, 'r') as data:\n",
    "        rawdata = data['kspace'][slice]\n",
    "                      \n",
    "    slice_kspace = T.to_tensor(rawdata).unsqueeze(0)\n",
    "    S, Ny, Nx, ps = slice_kspace.shape\n",
    "\n",
    "    # apply random mask\n",
    "    shape = np.array(slice_kspace.shape)\n",
    "    mask_func = MaskFunc(center_fractions=[center_fract], accelerations=[acc])\n",
    "    seed = None if not use_seed else tuple(map(ord, fname))\n",
    "    mask = mask_func(shape, seed)\n",
    "      \n",
    "    # undersample\n",
    "    masked_kspace = torch.where(mask == 0, torch.Tensor([0]), slice_kspace)\n",
    "    masks = mask.repeat(S, Ny, 1, ps)\n",
    "\n",
    "    img_gt, img_und = T.ifft2(slice_kspace), T.ifft2(masked_kspace)\n",
    "\n",
    "    # perform data normalization which is important for network to learn useful features\n",
    "    # during inference there is no ground truth image so use the zero-filled recon to normalize\n",
    "    norm = T.complex_abs(img_und).max()\n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "    # normalized data\n",
    "    img_gt, img_und, rawdata_und = img_gt/norm, img_und/norm, masked_kspace/norm\n",
    "        \n",
    "    return img_gt.squeeze(0), img_und.squeeze(0), rawdata_und.squeeze(0), masks.squeeze(0), norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {} # initiate the data list\n",
    "    train_and_val = ['train', 'val'] # set the keys in data list\n",
    "    data_path = [train_data_path, val_data_path] # import the data path for both training and validation\n",
    "      \n",
    "    for i in range(len(data_path)): # iterate on both paths\n",
    "\n",
    "        data_list[train_and_val[i]] = [] # reset the data list \n",
    "        \n",
    "        which_data_path = data_path[i] # set the data path to current dataset\n",
    "    \n",
    "        for fname in sorted(os.listdir(which_data_path)): # iterate on all listed files in the data path\n",
    "            \n",
    "            subject_data_path = os.path.join(which_data_path, fname) # set subject data path with its directory\n",
    "                     \n",
    "            if not os.path.isfile(subject_data_path): continue # iterate until all files are registered on path\n",
    "            \n",
    "            with h5py.File(subject_data_path, 'r') as data: # open the subject at the desinated path\n",
    "                num_slice = data['kspace'].shape[0] # set # of slices as the 1st-D of the data's kspace data\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(fname, subject_data_path, slice) for slice in range(5, num_slice)]\n",
    "            # data_list is concatenated by a list each consisted with a file's name, path and slices excluding \n",
    "            # the first 5 slices that are  mostly considered as noise \n",
    "            \n",
    "    return data_list # {'train': [('file1000000.h5','/home/kevinxu/Documents/NC2019MRI/train/file1000000.h5',5)？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': # main() function of the file\n",
    "    \n",
    "    data_path_train = '/home/kevinxu/Documents/NC2019MRI/train'\n",
    "    data_path_val = '/home/kevinxu/Documents/NC2019MRI/train'\n",
    "    data_list = load_data_path(data_path_train, data_path_val) # first load all file names, paths and slices.\n",
    "\n",
    "    acc = 8 # AF\n",
    "    cen_fract = 0.04 # central fraction that are set to be included\n",
    "    seed = False # random masks for each slice  用来随机生成mask\n",
    "    num_batch = 1 # batch size of each loading process 每次处理一张图片\n",
    "    num_workers = 12 # data loading is faster using a bigger number for num_workers. 0 means using cpu. 多线程处理多张图片\n",
    "    \n",
    "    # create data loader for training set. It applies same to validation set as well\n",
    "    train_dataset = MRIDataset(data_list['train'], acceleration=acc, center_fraction=cen_fract, use_seed=seed)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=num_batch, num_workers=num_workers) \n",
    "    for iteration, sample in enumerate(train_loader):\n",
    "        \n",
    "        img_gt, img_und, rawdata_und, masks, norm = sample\n",
    "         \n",
    "        # stack different slices into a volume for visualisation\n",
    "        A = masks[...,0].squeeze()    # mask applied\n",
    "        B = torch.log(T.complex_abs(rawdata_und) + 1e-9).squeeze()    # masked kspace image\n",
    "        C = T.complex_abs(img_und).squeeze()    # image generated from under-sampled data\n",
    "        D = T.complex_abs(img_gt).squeeze()    # image generated from ground truth data\n",
    "        all_imgs = torch.stack([A,B,C,D], dim=0)\n",
    "\n",
    "        # from left to right: mask, masked kspace, undersampled image, ground truth\n",
    "        show_slices(all_imgs, [0, 1, 2, 3], cmap='gray')\n",
    "        plt.pause(0.1)\n",
    "\n",
    "        if iteration >= 3: break  # show 4 random slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subsample is used to apply random mask for k-space data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskFunc:\n",
    "\n",
    "    def __init__(self, center_fractions, accelerations):\n",
    "       \n",
    "        if len(center_fractions) != len(accelerations):\n",
    "            raise ValueError('Number of center fractions should match number of accelerations')\n",
    "\n",
    "        self.center_fractions = center_fractions\n",
    "        self.accelerations = accelerations\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    def __call__(self, shape, seed=None):\n",
    "\n",
    "        if len(shape) < 3:\n",
    "            raise ValueError('Shape should have 3 or more dimensions')\n",
    "\n",
    "        self.rng.seed(seed)\n",
    "        num_cols = shape[-2]\n",
    "\n",
    "        choice = self.rng.randint(0, len(self.accelerations))\n",
    "        center_fraction = self.center_fractions[choice]\n",
    "        acceleration = self.accelerations[choice]\n",
    "\n",
    "        num_low_freqs = int(round(num_cols * center_fraction))\n",
    "        prob = (num_cols / acceleration - num_low_freqs) / (num_cols - num_low_freqs)\n",
    "        mask = self.rng.uniform(size=num_cols) < prob\n",
    "        pad = (num_cols - num_low_freqs + 1) // 2\n",
    "        mask[pad:pad + num_low_freqs] = True\n",
    "\n",
    "        mask_shape = [1 for _ in shape]\n",
    "        mask_shape[-2] = num_cols\n",
    "        mask = torch.from_numpy(mask.reshape(*mask_shape).astype(np.float32))\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The U-NET model has been described in the design part. So, in this part, I decide show some details. The channels of input images and output images are set one, and the kernels' channels are 64 which means after we did the stride-2 convolutional operation, leading to 64 channels images. Because the value of drop probability is 0.5，each layer will randomly drop approximate 50 percent cells. Besides, experimenters set the value of number of pool layers is 3.Three pool layers means the ConvBlock will be operated three times in down sampling and twice in up sampling.\n",
    " - In the training part, we choose the L1 loss function. In addition, we adopt the Stochastic Gradient Decent(SGD) optimizer which is the most basic optimization method and common training methods. Then, the value of learning rate we set is 0.01.Finally, we can train the data by forward propagation and back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UnetModel(in_chans=1, out_chans=1, chans=64, num_pool_layers=3, drop_prob=0.5).to(device)\n",
    "loss = torch.nn.L1Loss()\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.01)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() #initialize gradient to zero\n",
    "        output = model(data) #Finding the predicted value using forward propagation\n",
    "        loss.backward() #Back propagation to find the gradient\n",
    "        optimizer.step() #Update all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
