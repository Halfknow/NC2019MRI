{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tIntroduction [5%] (Xia)\n",
    "o\tdatasets: check fastMRI.org, read <fastMRI dataset> report, describe the dataset we get, introduce kspace data property and usage, explore the parameters of the training and test data\n",
    "o\ttask: machine learning task (check MRI_tutorial_note.py top)\n",
    "o\tgoals: what to achieve (check MRI_tutorial_note.py top)\n",
    "2.\tDesign [15%] (Wang, Zhou)\n",
    "o\tneural network description and justification: introduce adopted customised convolutional net and u-net, their structures, properties, expected performance and why they are chosen (justification)\n",
    "o\texperiment factors: first introduce the basic pipeline of the experiment (check mindmap), then choose important/ malleable factors in the steps to experiment with\n",
    "3.\tImplementation [20%] (Liu, Zhou)\n",
    "o\thow to implement in detail: data processing and coding structure\n",
    "o\tperformance analysis mechanisms: training, testing methods, metrics (SSIM)\n",
    "o\tcomments in the code: finished code to-date already commented\n",
    "4.\tExperiments [45%] (Xu) /with other two if cannot be finished in time\n",
    "o\tdescription of experiments to optimise generalization performance\n",
    "o\tresults presentation, presented in a statistical rigourous manner\n",
    "o\thow the training and test data sets are used\n",
    "5.\tConclusions [10%] (Xia)\n",
    "o\tkey findings: check references' structure and expression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) kspace data and fMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the long acquisition time in MRI often exceeds half an hour which results in low patient throughput. Hence, normal MRI with long acquisition time increases the exam costs and has lots of problems with patient comfort and compliance. People gradually pay more and more attention on safety problems caused by its long duration in MRI machines. Some acute diseases such as acute ischemic stroke, acute intracranial hemorrhage, acute abdominal pain requires the treatment measures can provide fast and valid judgement on the state of illness since long diagnosis time will deteriorate the patients' condition and lead to secondary injury.\n",
    "\n",
    "In our project, dataset is first preprocessed to get some values for later measurements such as ground truth. After preprocess, we concentrate on undersampling methods called Cartesian undersampling trajectory, respectively 4-fold acceleration and 8-fold acceleration, to accelerate the process of MRI scanning, which is the main process to reduce the scanning time significantly from more than half an hour to only a few minustes. However, after undersampling image quality will be affected, therefore, we try two models CNN and U-Net to reconstruct the undersampled MRI data to obtain more clear images. In result, U-Net deep learning model is more suitable to reconstruct the undersampled images, which will be used as our final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) neural network description and justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 CNN\n",
    "CNN(Convolutional Neural Networks) are consists of five components:\n",
    "\n",
    "The input layer requires data inputted for preprocessing operations, therefore, we transform the data shape from 3 dimension to 4 dimension.\n",
    "The convolution layer introduce a concept of local perception, which tells that in the process of the human brain recognizing a picture, the whole picture is not recognized at the same time, but each feature in the picture is first perceived locally, and then the local operation is comprehensively performed at a higher level to obtain global information. We construct a CNN model that has three convolution layer, the first two convolution layer use 16 filters and the kernel size is 5 * 5. And the third convolution layer adopt one 1 * 1 kernel size aiming to reduce the dimension of image.\n",
    "The activation layer makes a non-linear mapping of the output of the convolution layer. In this model, we choose the ReLU function, because iteration is faster.\n",
    "The pooling layer mainly used for feature dimension reduction, compressing the number of data and parameters, reducing overfitting, and improving the fault tolerance of the model. We choose a max pooling over a (2, 2) window. Finally, the feature maps are converted to a 1-dimensional vector by up sampling and the third convolution layer.\n",
    "The output layer which also called fully connected layer. After several previous convolutions, activations, and pooling, the model will fully learn a high-quality feature picture fully connected layer.\n",
    "CNN can directly process grayscale images and can be used directly to process image-based classification. CNN has unique advantages in image processing due to its special structure of local weight sharing. The layout is closer to the real biological neural network. Weight sharing reduces the complexity of the network, especially for multidimensional input vectors. The feature that allows images to be directly entered on the network avoids the complexity of rebuilding data when retrieving and classifying features.Maybe the performance of CNN used for MRI processing is not well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-NET model are mainly composed of two parts :\n",
    "\n",
    "- Down sampling part is also called the feature extraction. U-NET starts with one channel. Firstly, each convolutional layer did stride-2 convolution operations, and then we encapsulate these two convolution layers into a class ConvBlock. Specifically, each convolution layer followed by kernel, instance normalization, ReLU activation and drop out, kernel size is 3 * 3 and the number of channels doubles after the first convolution operation, and remains the same the second time.They lose two pixels for every stride-2 convolution because of a lack of padding.After the first 3X3 convolution operation after each pooling layer, the number of 3X3 convolution kernels doubles. Dropout is often used to randomly delete some neurons in a neural network to prevent overfitting and optimize the model by using normalization at the same time. Then, We choose a max pooling over a (2, 2) window used to half the size of feature map. Then again, the convolution and max-pooling steps are followed until the last pool layer. The number of pool layers depends on experimenters.\n",
    "- Up sampling, which is also known as deconvolution, or transpose convolution, is a critical part of U-net. There is a way, know as bilinear interpolation which means the feature map merged at the same scale as the number of channels corresponding to the feature extraction part. Therefore, before merging, the model will copy and crop the feature map in the shallow layers, which results in the final output is a region in the center of the input.After the first 3x3 convolution operation after each merging, the number of 3X3 convolution kernels becomes half. Unlike down sampling, up sampling double the size of image. And then passing through ConvBlock. Finally, in the last layer, we use the kernel 1 * 1 to accept the output image.\n",
    "U-NET is derived from CNN. U-shaped structure is the biggest feature of U-NET. U-NET performs several down sampling and use the contact connection on the corresponding layer, which ensured that the finally recovered feature maps incorporated more low-level features. Multiple up sampling also makes the information such as edge restoration of the image more detailed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) experiment factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) how to implement in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) performance analysis mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) comments in code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) description of experiments to optimise generalization performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) results presentation in a statistical rigourous manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) how the training and test datasets are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) key findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Description of Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
